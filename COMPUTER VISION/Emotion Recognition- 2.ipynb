{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-20T16:58:12.543917Z",
     "iopub.status.busy": "2023-11-20T16:58:12.543582Z",
     "iopub.status.idle": "2023-11-20T16:58:27.922905Z",
     "shell.execute_reply": "2023-11-20T16:58:27.921871Z",
     "shell.execute_reply.started": "2023-11-20T16:58:12.543889Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:00:19.792652Z",
     "iopub.status.busy": "2023-11-20T17:00:19.791549Z",
     "iopub.status.idle": "2023-11-20T17:00:19.800579Z",
     "shell.execute_reply": "2023-11-20T17:00:19.799336Z",
     "shell.execute_reply.started": "2023-11-20T17:00:19.792614Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mediapipe as mp \n",
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adagrad, Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization ,Activation \n",
    "import keras \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, Flatten, Dense,InputLayer ,Conv2D ,MaxPool2D\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:03:17.295184Z",
     "iopub.status.busy": "2023-11-20T17:03:17.294348Z",
     "iopub.status.idle": "2023-11-20T17:03:17.581436Z",
     "shell.execute_reply": "2023-11-20T17:03:17.580396Z",
     "shell.execute_reply.started": "2023-11-20T17:03:17.295144Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "LEFT_EYE = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\n",
    "RIGHT_EYE = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))\n",
    "LEFT_EYEBROW = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYEBROW)))\n",
    "RIGHT_EYEBROW = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYEBROW)))\n",
    "LIPS = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))\n",
    "CONTOURS = list(set(itertools.chain(*mp_face_mesh.FACEMESH_CONTOURS)))\n",
    "OTHER = [1]\n",
    "face_mesh = mp_face_mesh.FaceMesh(  \n",
    "                                    static_image_mode=True,\n",
    "                                    max_num_faces=1,\n",
    "                                    refine_landmarks=True,\n",
    "                                    min_detection_confidence=0.5)\n",
    "img=cv2.imread('/kaggle/input/emotion-detection-fer/test/happy/im1023.png')\n",
    "#img=cv2.imread(df['image_path'][1])\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (500, 500)) # Any size, just for visualization\n",
    "img = cv2.GaussianBlur(img, (3, 3), cv2.BORDER_DEFAULT)\n",
    "img_shape = img.shape[0]\n",
    "print(\"sahpe of the image it should be 500\",img_shape)\n",
    "results = face_mesh.process(img)\n",
    "print(\"the results\",results)\n",
    "annotated_image = img.copy()\n",
    "shape = [(lmk.x, lmk.y, lmk.z) for i, lmk in enumerate(results.multi_face_landmarks[0].landmark)]\n",
    "\n",
    "shape = np.array(shape)\n",
    "print(shape[1])\n",
    "print(\"======\")\n",
    "print(len(shape))  #x,y,z #this after normalization\n",
    "shape = shape[LEFT_EYE + RIGHT_EYE + LEFT_EYEBROW + RIGHT_EYEBROW + LIPS + OTHER]\n",
    "print(\"the shape of the it \",shape.shape)\n",
    "for lmk in shape:\n",
    "    cv2.circle(annotated_image, (int(lmk[0] * img_shape), int(lmk[1] * img_shape)), 2, (0, 0, 255))\n",
    "plt.imshow(annotated_image, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:04:05.019084Z",
     "iopub.status.busy": "2023-11-20T17:04:05.018687Z",
     "iopub.status.idle": "2023-11-20T17:17:41.439131Z",
     "shell.execute_reply": "2023-11-20T17:17:41.438035Z",
     "shell.execute_reply.started": "2023-11-20T17:04:05.019051Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PTH = '/kaggle/input/emotion-detection-fer'\n",
    "train_path = f'{PTH}/train'  \n",
    "test_path = f'{PTH}/test'\n",
    "\n",
    "def euc2d(a, b): # in 2d dimension\n",
    "    return np.sqrt( (a[0]-b[0])*(a[0]-b[0]) + (a[1]-b[1])*(a[1]-b[1]) )\n",
    "\n",
    "def euc3d(a, b):#in third dimension\n",
    "    return np.sqrt( (a[0]-b[0])*(a[0]-b[0]) + (a[1]-b[1])*(a[1]-b[1]) + (a[2]-b[2])*(a[2]-b[2]) )\n",
    "\n",
    "def prepare_csv(path, mode, face_mesh):\n",
    "    \n",
    "    emotions = os.listdir(path) #all directores of the train or the test the emotion exactly\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "    #he choose the 92 becouse the range(5) => 0-4 so it will be acually a 5 number \n",
    "    # *2  is to be x and y \n",
    "    }, columns = [f\"{i}\" for i in range(92 * 2)] + [\"y\"])\n",
    "    \n",
    "    \n",
    "    for i, emotion in enumerate(emotions): #also i we make it as labels\n",
    "        images = os.listdir(f'{path}/{emotion}')\n",
    "        for image in images:\n",
    "            #pre process of the image\n",
    "            img = cv2.imread(f\"{path}/{emotion}/{image}\")\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.GaussianBlur(img, (3, 3), cv2.BORDER_DEFAULT)\n",
    "            \n",
    "            results = face_mesh.process(img)\n",
    "        \n",
    "            if results.multi_face_landmarks:\n",
    "        \n",
    "                shape = [(lmk.x, lmk.y, lmk.z) for lmk in results.multi_face_landmarks[0].landmark]\n",
    "                shape = np.array(shape) #all thing\n",
    "                nose = shape[1] #the nose of the shape\n",
    "                shape = shape[LEFT_EYE + RIGHT_EYE + LEFT_EYEBROW + RIGHT_EYEBROW + LIPS] \n",
    "                #the interested indexes from the landmark \n",
    "\n",
    "                distances2d = [round(euc2d(nose, x), 6) for x in shape]\n",
    "                distances3d = [round(euc3d(nose, x), 6) for x in shape]\n",
    "\n",
    "                df.loc[len(df)] = distances2d + distances3d + [i] #need more inveseitigation\n",
    "            \n",
    "    df.to_csv(f'{mode}.csv', index=False)\n",
    "\n",
    "\n",
    "prepare_csv(train_path, 'train', face_mesh)\n",
    "prepare_csv(test_path, 'test', face_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:19:58.222738Z",
     "iopub.status.busy": "2023-11-20T17:19:58.222289Z",
     "iopub.status.idle": "2023-11-20T17:19:59.121025Z",
     "shell.execute_reply": "2023-11-20T17:19:59.12012Z",
     "shell.execute_reply.started": "2023-11-20T17:19:58.222703Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/kaggle/working/train.csv')\n",
    "df_test=pd.read_csv('/kaggle/working/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:20:13.908445Z",
     "iopub.status.busy": "2023-11-20T17:20:13.907811Z",
     "iopub.status.idle": "2023-11-20T17:20:13.935644Z",
     "shell.execute_reply": "2023-11-20T17:20:13.934751Z",
     "shell.execute_reply.started": "2023-11-20T17:20:13.908401Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:20:19.957309Z",
     "iopub.status.busy": "2023-11-20T17:20:19.956407Z",
     "iopub.status.idle": "2023-11-20T17:20:19.982499Z",
     "shell.execute_reply": "2023-11-20T17:20:19.981448Z",
     "shell.execute_reply.started": "2023-11-20T17:20:19.957276Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:21:07.913208Z",
     "iopub.status.busy": "2023-11-20T17:21:07.912835Z",
     "iopub.status.idle": "2023-11-20T17:21:07.919461Z",
     "shell.execute_reply": "2023-11-20T17:21:07.918553Z",
     "shell.execute_reply.started": "2023-11-20T17:21:07.913178Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:21:14.332088Z",
     "iopub.status.busy": "2023-11-20T17:21:14.331396Z",
     "iopub.status.idle": "2023-11-20T17:21:14.337835Z",
     "shell.execute_reply": "2023-11-20T17:21:14.336908Z",
     "shell.execute_reply.started": "2023-11-20T17:21:14.332055Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:33:00.305722Z",
     "iopub.status.busy": "2023-11-20T17:33:00.305343Z",
     "iopub.status.idle": "2023-11-20T17:33:00.311602Z",
     "shell.execute_reply": "2023-11-20T17:33:00.310509Z",
     "shell.execute_reply.started": "2023-11-20T17:33:00.305686Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                        brightness_range=[0.1, 1.5],\n",
    "                        rotation_range=5, # rotate the image 30 degrees\n",
    "                        width_shift_range=0.1, # Shift the pic width by a\n",
    "                        height_shift_range=0.1, # Shift the pic height by\n",
    "                        rescale=1./255, # Rescale the image by normalzing\n",
    "                        shear_range=0.2, # Shear means cutting away part o\n",
    "                        zoom_range=0.3, # Zoom in by 20% max\n",
    "                        horizontal_flip=True, # Allow horizontal flipping\n",
    "                        fill_mode='nearest', # Fill in missing pixels with\n",
    "                        validation_split=0.3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:33:03.351448Z",
     "iopub.status.busy": "2023-11-20T17:33:03.3506Z",
     "iopub.status.idle": "2023-11-20T17:33:17.571094Z",
     "shell.execute_reply": "2023-11-20T17:33:17.570106Z",
     "shell.execute_reply.started": "2023-11-20T17:33:03.351396Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = (48, 48)  # Target image size\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    '/kaggle/input/emotion-detection-fer/train/',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode='categorical',\n",
    "    subset='training'       # 'training' or 'validation'\n",
    "    \n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    '/kaggle/input/emotion-detection-fer/train',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:34:20.430693Z",
     "iopub.status.busy": "2023-11-20T17:34:20.430034Z",
     "iopub.status.idle": "2023-11-20T19:24:04.871944Z",
     "shell.execute_reply": "2023-11-20T19:24:04.870909Z",
     "shell.execute_reply.started": "2023-11-20T17:34:20.430656Z"
    }
   },
   "outputs": [],
   "source": [
    "train_n = train_generator.n\n",
    "val_n = validation_generator.n\n",
    "image_shape=(48,48,3)\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=image_shape))\n",
    "\n",
    "# 1 CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation=activations.swish))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation=activations.swish))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation=activations.swish))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation=activations.swish))\n",
    "\n",
    "# POOLING LAYER\n",
    "model.add(MaxPool2D(pool_size=(3, 3)))\n",
    "\n",
    "# 2 CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation=activations.swish))\n",
    "# POOLING LAYER\n",
    "model.add(MaxPool2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='swish'))\n",
    "model.add(Dense(256, activation='swish'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss = losses.CategoricalCrossentropy(),\n",
    "                        optimizer = Adam(learning_rate=0.0003),\n",
    "                        metrics = ['accuracy'])\n",
    "results = model.fit(train_generator, epochs=100,\n",
    "                    steps_per_epoch=train_n//batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=val_n//batch_size)\n",
    "model.save('best_fer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T19:26:32.762278Z",
     "iopub.status.busy": "2023-11-20T19:26:32.761636Z",
     "iopub.status.idle": "2023-11-20T19:27:35.970441Z",
     "shell.execute_reply": "2023-11-20T19:27:35.969478Z",
     "shell.execute_reply.started": "2023-11-20T19:26:32.762242Z"
    }
   },
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_generator, verbose= 1)\n",
    "valid_score = model.evaluate(validation_generator,  verbose= 1)\n",
    "# test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 40)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T19:26:05.90846Z",
     "iopub.status.busy": "2023-11-20T19:26:05.908063Z",
     "iopub.status.idle": "2023-11-20T19:26:06.395882Z",
     "shell.execute_reply": "2023-11-20T19:26:06.394765Z",
     "shell.execute_reply.started": "2023-11-20T19:26:05.908405Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_validation(history):\n",
    "    fig , ax = plt.subplots(1,2)\n",
    "    train_acc = results.history['accuracy']\n",
    "    train_loss = results.history['loss']\n",
    "    fig.set_size_inches(12,4)\n",
    "\n",
    "    ax[0].plot(results.history['accuracy'])\n",
    "    ax[0].plot(results.history['val_accuracy'])\n",
    "    ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    ax[1].plot(results.history['loss'])\n",
    "    ax[1].plot(results.history['val_loss'])\n",
    "    ax[1].set_title('Training Loss vs Validation Loss')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "plot_accuracy_validation(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T19:32:40.164099Z",
     "iopub.status.busy": "2023-11-20T19:32:40.163508Z",
     "iopub.status.idle": "2023-11-20T19:32:59.124365Z",
     "shell.execute_reply": "2023-11-20T19:32:59.12349Z",
     "shell.execute_reply.started": "2023-11-20T19:32:40.164062Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "Y_pred = model.predict_generator(validation_generator, val_n // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "CLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "cm_data = confusion_matrix(validation_generator.classes, y_pred)\n",
    "cm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.title('Confusion Matrix', fontsize = 20)\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')\n",
    "target_names = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1028436,
     "sourceId": 1732825,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
