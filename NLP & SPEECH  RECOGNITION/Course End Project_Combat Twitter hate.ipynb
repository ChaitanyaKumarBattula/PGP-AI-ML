{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks: \n",
    "\n",
    "## 1] Load the tweets file using read_csv function from Pandas package. \n",
    "\n",
    "\n",
    "## 2] Get the tweets into a list for easy text cleanup and manipulation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3] To cleanup: \n",
    "\n",
    "##### 3.1] Normalize the casing.\n",
    "\n",
    "##### 3.2] Using regular expressions, remove user handles. These begin with '@’.\n",
    "\n",
    "##### 3.3] Using regular expressions, remove URLs.\n",
    "\n",
    "##### 3.5] Remove stop words.\n",
    "\n",
    "##### 3.6] Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
    "\n",
    "##### 3.7] Remove ‘#’ symbols from the tweet while retaining the term.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 4] Extra cleanup by removing terms with a length of 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 5] Check out the top terms in the tweets:\n",
    "\n",
    "##### 5.1] First, get all the tokenized terms into one large list.\n",
    "\n",
    "#####  5.2] Use the counter and find the 10 most common terms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 6] Data formatting for predictive modeling:\n",
    "\n",
    "#####  6.1] Join the tokens back to form strings. This will be required for the vectorizers.\n",
    "\n",
    "#####  6.2] Assign x and y.\n",
    "\n",
    "#####  6.3] Perform train_test_split using sklearn.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 7] We’ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "\n",
    "#####  7.1] Import TF-IDF  vectorizer from sklearn.\n",
    "\n",
    "#####  7.2] Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "\n",
    "#####  7.3] Fit and apply on the train set.\n",
    "\n",
    "#####  7.4] Apply on the test set.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 8] Model building: Ordinary Logistic Regression\n",
    "\n",
    "#####  8.1] Instantiate Logistic Regression from sklearn with default parameters.\n",
    "\n",
    "#####  8.2] Fit into  the train data.\n",
    "\n",
    "##### 8.3] Make predictions for the train and the test set.\n",
    "\n",
    "\n",
    "\n",
    "## 9] Model evaluation: Accuracy, recall, and f_1 score.\n",
    "\n",
    "#####  9.1] Report the accuracy on the train set.\n",
    "\n",
    "#####  9.2] Report the recall on the train set: decent, high, or low.\n",
    "\n",
    "#####  9.3] Get the f1 score on the train set.\n",
    "\n",
    "\n",
    "\n",
    "##  10] Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s.\n",
    "\n",
    "#####  10.1]Adjust the appropriate class in the LogisticRegression model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 11] Train again with the adjustment and evaluate.\n",
    "\n",
    "##### 11.1] Train the model on the train set.\n",
    "\n",
    "#####  11.2] Evaluate the predictions on the train set: accuracy, recall, and f_1 score.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 12] Regularization and Hyperparameter tuning:\n",
    "\n",
    "#####  12.1] Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "\n",
    "#####  12.2] Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
    "\n",
    "#####  12.3] Use a balanced class weight while instantiating the logistic regression.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 13] Find the parameters with the best recall in cross-validation.\n",
    "\n",
    "#####  13.1] Choose ‘recall’ as the metric for scoring.\n",
    "\n",
    "#####  13.2] Choose a stratified 4 fold cross-validation scheme.\n",
    "\n",
    "### 13.3] Fit into  the train set.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####  14] What are the best parameters?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 15] Predict and evaluate using the best estimator.\n",
    "\n",
    "#####  15.1] Use the best estimator from the grid search to make predictions on the test set.\n",
    "\n",
    "#####  15.2] What is the recall on the test set for the toxic comments?\n",
    "\n",
    "#####  15.3] What is the f_1 score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT  CODE   STARTS   FROM  HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-1]\n",
    "Load the tweets file using read_csv function from Pandas package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import os, re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task  1.1      Load Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"TwitterHate.csv\")\n",
    "# View sample data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Task  1.2         Understand Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of rows: 31962\n",
      "Number of columns : 3\n",
      "\n",
      "Data Info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Number Of rows\n",
    "\n",
    "number_of_rows = len(df.index)\n",
    "number_of_cols = len(df.columns)\n",
    "print(\"Number Of rows:\",  number_of_rows)\n",
    "print('Number of columns :', number_of_cols)\n",
    "print()\n",
    "print(\"Data Info\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    Task  1.3    data Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22037</th>\n",
       "      <td>22038</td>\n",
       "      <td>0</td>\n",
       "      <td>the highest happiness on eah is the happiness ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30710</th>\n",
       "      <td>30711</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm   for the #weekend and i will #sing to my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>âfeeling  ! just staed my own  #avon busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "22037  22038      0  the highest happiness on eah is the happiness ...\n",
       "30710  30711      0  i'm   for the #weekend and i will #sing to my ...\n",
       "1279    1280      0  âfeeling  ! just staed my own  #avon busines..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling 0.01%  of data randomly \n",
    "\n",
    "rows = df.sample(frac =0.0001)\n",
    "\n",
    "# display\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20552</th>\n",
       "      <td>20553</td>\n",
       "      <td>0</td>\n",
       "      <td>happy weekend.. ðð¯ #girls #friends #week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8026</th>\n",
       "      <td>8027</td>\n",
       "      <td>0</td>\n",
       "      <td>for freedom friday @user @user @user @user w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26645</th>\n",
       "      <td>26646</td>\n",
       "      <td>0</td>\n",
       "      <td>twinklatinboys - na: #slut #snapshot #hot #nas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "20552  20553      0  happy weekend.. ðð¯ #girls #friends #week...\n",
       "8026    8027      0    for freedom friday @user @user @user @user w...\n",
       "26645  26646      0  twinklatinboys - na: #slut #snapshot #hot #nas..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling 3nos of data randomly \n",
    "\n",
    "rows = df.sample(n = 3)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8830    great sta to #euro2016 last night with a great...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample any one row randomly\n",
    "\n",
    "df.tweet.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anyone else have that one family member (related through marriage) that thrives off back stabbing your actual family?? #grrr   #ikeelu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweet.sample().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Task  1.4       Inspect for Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Unique values in The label Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     2242\n",
       "0    29720\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain relative frequencies of the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x273675b10a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"label\"].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-2\n",
    "Get the tweets into a list for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_List = df[\"tweet\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Tweets_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Tweets_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task.3\n",
    "## To cleanup: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1] Normalize the casing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All text Coverted to lowercase !!\n"
     ]
    }
   ],
   "source": [
    "def to_lowercase(Tweets_List):\n",
    "    Tweets_Lowercase = []\n",
    "    for tweet in Tweets_List:\n",
    "        Tweets_Lowercase.append(tweet)\n",
    "    \n",
    "    return Tweets_Lowercase\n",
    "\n",
    "Tweets_Lowercase = to_lowercase(Tweets_List)\n",
    "\n",
    "print(\"All text Coverted to lowercase !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 3.2]:\n",
    "Using regular expressions, remove user handles. These begin with '@’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All User Handles removed from The text !!!\n"
     ]
    }
   ],
   "source": [
    "def remove_user_handles(Tweets_Lowercase):\n",
    "    hashes_removed = [re.sub(\"@\\w+\",\"\", tweet) for tweet in Tweets_Lowercase]\n",
    "    return(hashes_removed)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tweets_Without_User_Handles =  remove_user_handles(Tweets_Lowercase)\n",
    "print(\"All User Handles removed from The text !!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task- 3.3\n",
    "Using regular expressions, remove URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All URLs remved form the text !!\n"
     ]
    }
   ],
   "source": [
    "def remove_URL(Tweets_Without_User_Handles):\n",
    "    URL_removed = [re.sub(\"\\w+://\\S+\",\"\", Tweet) for Tweet in Tweets_Without_User_Handles]\n",
    "    return(URL_removed)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Tweets_Without_URL =  remove_URL(Tweets_Without_User_Handles)\n",
    "print(\"All URLs remved form the text !!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task- 3.4\n",
    "Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the text converted to tokens !!\n"
     ]
    }
   ],
   "source": [
    "def Tokenize(Tweets_Without_URL):\n",
    "    t = TweetTokenizer()\n",
    "    Tokens = [t.tokenize(Tweet) for Tweet in Tweets_Without_URL]\n",
    "    return Tokens\n",
    "\n",
    "\n",
    "Tweet_Tokens  = Tokenize(Tweets_Without_URL)\n",
    "\n",
    "\n",
    "print(\"All the text converted to tokens !!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task- 3.5\n",
    "Remove stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All STOPWORDS removed from the text !!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def Remove_StopWords(Tweet_Token):\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    Without_StopWords = [Term for Term in Tweet_Token if not Term in stop_words]\n",
    "    return Without_StopWords\n",
    "\n",
    "Tweets_Without_StopWords =  [Remove_StopWords(Tweet_Token) for Tweet_Token in Tweet_Tokens ]\n",
    " \n",
    "print(\"All STOPWORDS removed from the text !!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task- 3.6\n",
    "Remove redundant terms like ‘amp’, ‘rt’, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Redunt words removed from the text !!\n"
     ]
    }
   ],
   "source": [
    "def Remove_Redunts(Tweets_Without_StopWords):\n",
    "    redunt_terms = ['rt', 'amp']\n",
    "    #Without_ReduntWords = [word for word in Tweets_Without_StopWords if not word in redunt_terms]\n",
    "    Without_ReduntWords = [word for word in Tweets_Without_StopWords if not word in redunt_terms]\n",
    "    return Without_ReduntWords\n",
    "\n",
    "Tweets_Without_Redunt_Words = Remove_Redunts(Tweets_Without_StopWords)\n",
    "print(\"All Redunt words removed from the text !!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task.3.7\n",
    "Remove ‘#’ symbols from the tweet while retaining the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Hashes(#) removed from the text !!\n"
     ]
    }
   ],
   "source": [
    "def Remove_Hash(Tweet):\n",
    "    return [re.sub(\"#\",\"\", term) for term in Tweet ]\n",
    "\n",
    "\n",
    "\n",
    "Tweets_Without_Hashes = [Remove_Hash(Tweet) for Tweet in Tweets_Without_Redunt_Words]\n",
    "\n",
    "\n",
    "print(\"All Hashes(#) removed from the text !!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  4.1 \n",
    "Extra Cleanup by removing terms with a length of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Single Letters removed from the text !!\n"
     ]
    }
   ],
   "source": [
    "def Remove_Single_Letter(Tweet):\n",
    "    Without_Single_Letter = [word for word in Tweet if (len(word)>1)]\n",
    "    return Without_Single_Letter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tweets_Without_Single_Letters  = [Remove_Single_Letter(Tweet) for Tweet in Tweets_Without_Hashes]\n",
    "\n",
    "print(\"All Single Letters removed from the text !!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.2\n",
    "Remove all types of Punctuations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All punctuations removed!!\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuations = list(punctuation)\n",
    "\n",
    "Additional_punctuations = ['...','``',\"''\",\"..\"]\n",
    "\n",
    "punctuations.extend(Additional_punctuations)\n",
    "\n",
    "def Remove_Punctuations(Tweet):\n",
    "    Without_Punctuations = [Term for Term in Tweet if Term not in punctuations]\n",
    "    return Without_Punctuations\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Cleaned_Tweets  = [Remove_Punctuations(Tweet) for Tweet in Tweets_Without_Single_Letters]\n",
    "print(\"All punctuations removed!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cleaned Tweets Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Tweets sample:\n",
      "[['bihday', 'majesty'], ['model', 'love', 'take', 'time', 'urð']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned Tweets sample:\")\n",
    "print(Cleaned_Tweets[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task.5\n",
    "Check out the top terms in the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 5.1\n",
    "First, get all the tokenized terms into one large list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251558"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge All word lists in to a single List of words so that counting can be done\n",
    "\n",
    "Merged_Tweets = []\n",
    "\n",
    "for Tweet in Cleaned_Tweets:\n",
    "    Merged_Tweets.extend(Tweet)\n",
    "    \n",
    "\n",
    "    \n",
    "len(Merged_Tweets  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  5.2 \n",
    "Use the counter and find the 10 most common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2748),\n",
       " ('day', 2276),\n",
       " ('happy', 1684),\n",
       " ('time', 1131),\n",
       " ('life', 1118),\n",
       " ('like', 1047),\n",
       " (\"i'm\", 1018),\n",
       " ('today', 1013),\n",
       " ('new', 994),\n",
       " ('thankful', 946)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "term_count = Counter(Merged_Tweets)\n",
    "term_count.most_common(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  5.3\n",
    "\n",
    "Graphical Representation of the Top ten common terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Create a  Df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>like</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i'm</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>today</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>new</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thankful</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words  count\n",
       "0      love   2748\n",
       "1       day   2276\n",
       "2     happy   1684\n",
       "3      time   1131\n",
       "4      life   1118\n",
       "5      like   1047\n",
       "6       i'm   1018\n",
       "7     today   1013\n",
       "8       new    994\n",
       "9  thankful    946"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_count_Df = pd.DataFrame(term_count.most_common(15),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "term_count_Df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   Plot Using the data in df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAE/CAYAAADR125OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhkdX3v8feHdRhnBBFUWhIHcQWEQRoim4J4TVxBlrggAnoZjCKJXr3ujnMTck1QL+JGRsMWERSUoFwVNLKLSLfsIqIsQsZ12DOACN/7R53Gom/3TM9MV1VXzfv1PPXMqV/9zu98Tx0bP8/vLJWqQpIkSYNnrV4XIEmSpM4w6EmSJA0og54kSdKAMuhJkiQNKIOeJEnSgDLoSZIkDSiDniSp45LskeT2XtchrWkMepKmVZL72l6PJLm/7f2B0zD+dW3jPZzkgbb3H5iOfWi286wkpyf5fZK7k1yd5F1J1p6ubfRSkp2T3NO+P0m+MEnbcb2pUtLqMuhJmlZVNWfsBfwSeFVb2ynTMP7WbeNfBBzRNv4/ru74AEm2BC4DbgOeV1UbAgcAw8Dc6djGDDACrA08v61td2DJuLYXAheuzMBJ1lnt6iRNC4OepK5Isn6SY5IsaV7HJFm/+WyPJLcn+UAzg3bLqsz+JXlzkuuT3JnknCRPa/uskrw1yY3N559NkkmGWgT8oKreVVW/AqiqG6rqDVV1VzPeq5vZxbuSnJ/kuW3buiXJe5pZwP9K8q9Jnpzk20nuTfK9JE9o+s5rajs0yW1NbW9NsmOz/l1JPtM29lpJPpTk1iS/TXJykg3HjXVwkl823+UHJ9rBqnoI+CGtIEeSJwHrAV8Z1/Ys4MIpHr/3Jvk1cEKSDZKc2OzPT4Adxx2r9yb5z+b7uCHJXlM8zJJWgkFPUrd8EHgBMB/YDtgJ+FDb508BNgGeChwMLE7y7KkOnmQf4APAvsCmtGb7Th3X7ZW0Asd2wF8DfznJcC8BzljOtp7VjP13zba+BXwzyXpt3fYD/hutoPQq4NtNfZvQ+m/vkeOG/QvgmcBrgWNofV8vAbYG/jrJi5p+hzSvPYGnA3OAz4wbazfg2cBewEfaQ+g4F9KEuubfi5tXe9vNVXU7Uzt+GwNPAxYAC4Etm9df0jqmADTH9Qhgx6qa23x+yyQ1SloNBj1J3XIg8L+q6rdV9Ttas2YHjevz4ap6sKouAP4vrTA2VYcD/7uqrq+qPwL/CMxvn9UDPlZVd1XVL4HzaIWWiTwR+NVytvVa4P9W1XebmbGPAxsAu7T1+XRV/aaq/pNW6Lysqq6oqgeBM4Htx43591X1QFWdC/wXcGrzXY2tP9b/QOCTVXVTVd0HvB943bjTpYuq6v6qugq4ilYwm8gFwG7NzObuzXYuBV7Q1nZB23aXd/weARY2x+9+WsfuqKq6o6puA45t6/swsD6wVZJ1q+qWqvrFJDVKWg0GPUndMgTc2vb+1qZtzJ1V9V/L+XxFngZ8qjnVeRdwBxBaM4Rjft22vIzWbNhElgKbLWdbj9mXqnqE1vV87dv6Tdvy/RO8H7/tqfaf6HtcB3hyW9tU9/OHzWfb0Jq9u6gJj7e1tY1dn7ei4/e7qnqg7f1QM057fwCq6ue0ZkM/Cvw2yWlJVuZYS5oig56kbllCK4yN+fOmbcwTkjxuOZ+vyG3A4VW1Udtrg6r6wSrU+j1ap14n85h9aWa//gz4z1XY1sqa6Hv8I48NhlPSBLPLaZ3S3qyqftp8dFHTti1/CnorOn41bvhf0fpO2vu3b/vLVbVbM2YB/7Sy9UtaMYOepG45FfhQkk2TbAJ8BPjSuD6LkqyXZHdaQeP0lRj/OOD9SbYGSLJhkgNWsdaFwC5Jjk7ylGa8ZyT5UpKNgK8Cr0iyV5J1gf8BPAisSqhcWacC70yyRZI5tE5Rf6U5Xb0qLqQ1u9Ze+8VN26/bTqlO5fi1+yqt4/GEJJsD7xj7IMmzk7y4uZnjAVozlg+vYv2SlsOgJ6lb/oHWIz2uBq4Bfty0jfk1cCetWaJTgLe2zTCtUFWdSWtW6LQk9wDXAi9blUKbcLMzMA+4LsndwNea+u+tqhuANwKfBn5P62aLV1XVH1ZleyvpeODfaAW0m2kFpXcsd43luwB4Eq1wN+bipq39sSorOn7jLaJ1uvZm4Nym5jHrAx+j9d39utnWtD0DUdKfpGr8bLskdVeSPYAvVdXmva5FkgaJM3qSJEkDyqAnSZI0oDx1K0mSNKCc0ZMkSRpQBj1JkqQBtc6Ku6yZNtlkk5o3b16vy5AkSVqh0dHR31fVpuPbDXqTmDdvHiMjI70uQ5IkaYWS3DpRu6duJUmSBpRBT5IkaUAZ9CRJkgZUX12jl+S+qprTjW0tGV3CoizqxqYkSdIAWlgLe12CM3qSJEmDqi+DXlqOTnJtkmuSvLZp/0qSl7f1OzHJfknWbvpfnuTqJIf3rnpJkqTu6MugB+wLzAe2A14CHJ1kM+A0YCz0rQfsBXwLeAtwd1XtCOwIHJZki14ULkmS1C39GvR2A06tqoer6jfABbQC3LeBFydZH3gZcGFV3Q+8FHhTkiuBy4AnAs8cP2iSBUlGkowsY1m39kWSJKkj+upmjDaZqLGqHkhyPvCXtGb2Tm3r/46qOmd5g1bVYmAxwFCGatqqlSRJ6oF+ndG7EHhtc+3dpsALgR81n50GHArsDowFu3OAv0myLkCSZyV5XJdrliRJ6qp+ndE7E9gZuAoo4H9W1a+bz84FTga+UVV/aNq+CMwDfpwkwO+AfbpasSRJUpf1VdAbe4ZeVRXwnuY1vs9DtK7Ba297BPhA85IkSVoj9FXQ66ahHYZYONL7Bx1KkiStqn69Rk+SJEkrYNCTJEkaUAY9SZKkAWXQkyRJGlAGPUmSpAFl0JMkSRpQBj1JkqQBZdCTJEkaUAPxwOQkHwXuq6qPT9eYS0aXsCiLpms4SZJmhIXljwGsSZzRkyRJGlB9G/SSfDDJDUm+Bzy7aTssyeVJrkrytSSzk8xNcnOSdZs+j09yy9h7SZKkQdWXQS/JDsDrgO2BfYEdm4++XlU7VtV2wPXAW6rqXuB84BVNn9cBX6uqh7pbtSRJUnf1ZdADdgfOrKplVXUP8I2mfZskFyW5BjgQ2Lpp/yJwaLN8KHDCRIMmWZBkJMnIMpZ1sHxJkqTO69egB1ATtJ0IHFFVzwMWAbMAquoSYF6SFwFrV9W1Ew5YtbiqhqtqeDazO1S2JElSd/Rr0LsQeE2SDZLMBV7VtM8FftVcf3fguHVOBk5lktk8SZKkQdOXQa+qfgx8BbgS+BpwUfPRh4HLgO8CPx232inAE2iFPUmSpIHXt8/Rq6qjgKMm+Ojzk6yyG3BGVd3VuaokSZJmjr4NeisjyaeBlwEvn+o6QzsMsXDEh0pKkqT+tUYEvap6R69rkCRJ6ra+vEZPkiRJK2bQkyRJGlAGPUmSpAFl0JMkSRpQBj1JkqQBZdCTJEkaUAY9SZKkATUjnqOXZB5wdlVt0+NSHrVkdAmLsqjXZUjSjLCwfIC81I+c0ZMkSRpQMynorZ3kC0muS3Jukg2SHJbk8iRXJflaktkASU5MclySi5L8LMkrm/ZDkpyV5DtJbkiysGn/+yR/O7ahJEclObI3uylJktQdMynoPRP4bFVtDdwF7Ad8vap2rKrtgOuBt7T1nwe8CHgFcFySWU37TsCBwHzggCTDwL8CBwMkWQt4HXBKx/dIkiSph2ZS0Lu5qq5slkdpBbltmlm7a2iFt63b+n+1qh6pqhuBm4DnNO3fraqlVXU/8HVgt6q6BViaZHvgpcAVVbV0fAFJFiQZSTKyjGWd2EdJkqSumRE3YzQebFt+GNgAOBHYp6quSnIIsEdbnxq3fq2g/YvAIcBTgOMnKqCqFgOLAYYyNH4cSZKkvjKTZvQmMhf4VZJ1ac3otTsgyVpJtgSeDtzQtP+3JBsn2QDYB7ikaT8T+CtgR+CczpcuSZLUWzNpRm8iHwYuA24FrqEV/MbcAFwAPBl4a1U9kATgYuDfgGcAX66qEYCq+kOS84C7qurh7u2CJElSb8yIoNdcQ7dN2/uPt338+UlWu6Sq3jlB+2+r6ojxjc1NGC8ADliNUiVJkvrGjAh6nZZkK+Bs4Mzm5o0VGtphiIUjPiBUkiT1r74MelV1yCTtJ9K6gWN8+09oXccnSZK0xpjpN2NIkiRpFRn0JEmSBpRBT5IkaUAZ9CRJkgaUQU+SJGlAGfQkSZIGlEFPkiRpQPXlc/S6YcnoEhZlUa/LkAbawvKh5JLUSTN+Ri/JRkne1iwPJTmj1zVJkiT1gxkf9ICNgLcBVNWSqtq/x/VIkiT1hX44dfsxYMskVwI3As+tqm2SHALsA6wNbAN8AlgPOAh4EHh5Vd2RZEvgs8CmwDLgsKr6afd3Q5Ikqbv6YUbvfcAvqmo+8J5xn20DvAHYCTgKWFZV2wOXAm9q+iwG3lFVOwDvBj432YaSLEgykmRkGcumeTckSZK6qx9m9JbnvKq6F7g3yd3AN5v2a4Btk8wBdgFOTzK2zvqTDVZVi2kFQ4YyVB2rWpIkqQv6Peg92Lb8SNv7R2jt21rAXc1soCRJ0hqlH07d3gvMXZUVq+oe4OYkBwCkZbvpLE6SJGmmmvFBr6qWApckuRY4ehWGOBB4S5KrgOuAvaezPkmSpJkqVV6KNpHh4eEaGRnpdRmSJEkrlGS0qobHt8/4GT1JkiStGoOeJEnSgDLoSZIkDSiDniRJ0oAy6EmSJA0og54kSdKAMuhJkiQNKIOeJEnSgOr337rtmCWjS1iURb0uQxpIC2thr0uQpDVC38/oJbmv+XcoyRlt7acmuTrJO3tXnSRJUu8MzIxeVS0B9gdI8hRgl6p6Wm+rkiRJ6p2+n9Ebk2Rekmubt+cCT0pyZZLdk2yZ5DtJRpNclOQ5vaxVkiSpGwZmRm+cVwNnV9V8gCT/Aby1qm5M8hfA54AX97JASZKkThvUoPeoJHOAXYDTk4w1rz9J3wXAAoAN2bAr9UmSJHXKwAc9Wqen7xqb3VueqloMLAYYylB1ujBJkqROGphr9CZTVfcANyc5ACAt2/W4LEmSpI4b+KDXOBB4S5KrgOuAvXtcjyRJUselyjOUExkeHq6RkZFelyFJkrRCSUaranh8+5oyoydJkrTGMehJkiQNKIOeJEnSgDLoSZIkDSiDniRJ0oAy6EmSJA0og54kSdKAMuhJkiQNqDXht25XyZLRJSzKol6XIc1oC2thr0uQJC1H387oJbmv+XcoyRnN8iFJPtPbyiRJkmaGvp/Rq6olwP69rkOSJGmm6dsZvTFJ5iW5doL2VyS5NMkmSV7aLP84yelJ5vSiVkmSpG7q+6A3kSSvAd4HvLxp+hDwkqp6PjACvKtXtUmSJHVL35+6ncCewDDw0qq6J8krga2AS5IArAdcOtGKSRYACwA2ZMPuVCtJktQhgxj0bgKeDjyL1uxdgO9W1etXtGJVLQYWAwxlqDpZpCRJUqcN4qnbW4F9gZOTbA38ENg1yTMAksxO8qxeFihJktQNgxj0qKobgAOB04HHA4cApya5mlbwe07vqpMkSeqOVHmGciLDw8M1MjLS6zIkSZJWKMloVQ2Pbx/IGT1JkiQZ9CRJkgaWQU+SJGlAGfQkSZIGlEFPkiRpQBn0JEmSBpRBT5IkaUAZ9CRJkgbUIP7W7bRYMrqERVnU6zKkGWFhLex1CZKkVdD3M3pJftD8Oy/J+T0uR5Ikacbo+6BXVbv0ugZJkqSZqO9P3Sa5r6rmAA8DdzRthwD7AGsD2wCfANYDDgIeBF5eVXf0pGBJkqQu6fsZvTFVdVtV7dvWtA3wBmAn4ChgWVVtD1wKvKkHJUqSJHXVwAS9CZxXVfdW1e+Au4FvNu3XAPMmWiHJgiQjSUaWsaxLZUqSJHXGIAe9B9uWH2l7/wiTnLKuqsVVNVxVw7OZ3en6JEmSOmqQg54kSdIazaAnSZI0oFJVva5hRhoeHq6RkZFelyFJkrRCSUaranh8+0rP6CV5QpJtp6csSZIkdcqUgl6S85M8PsnGwFXACUk+2dnSJEmStDqmOqO3YVXdA+wLnFBVOwAv6VxZkiRJWl1TDXrrJNkM+Gvg7A7WI0mSpGky1aD3v4BzgJ9X1eVJng7c2LmyJEmStLqm9Fu3VXU6cHrb+5uA/TpVlCRJklbfcoNekk8Dkz5/paqOnPaKJEmSNC1WdOp2BBgFZgHPp3W69kZgPvBwZ0uTJEnS6pjSA5OTnAe8tKoeat6vC5xbVXt2uL6eGcpQHc7hvS5D6rmFtbDXJUiSVmB1H5g8BMxtez+naZtWSTZK8raVXOfEJPtPdy2SJEn9bko3YwAfA65oZvYAXgR8tAP1bAS8DfhcB8aWJElao6ww6CVZC7gB+IvmBfC+qvp1B+r5GLBlkiuB7zZtL6N1Q8g/VNVXkgT4NPBi4GYgbbV+BHgVsAHwA+Bw4OnA6VX1/KbPM4HTmoc+S5IkDawVnrqtqkeAT1TVr6vqrObViZAH8D7gF1U1H/ghrZs+tqP1KxxHNw9tfg3wbOB5wGHALm3rf6aqdqyqbWiFvVdW1S+Au5PMb/ocCpzYofolSZJmjKleo3dukv2a2bRu2Q04taoerqrfABcAOwIvbGtfAny/bZ09k1yW5BpaM35bN+1fBA5NsjbwWuDLE20wyYIkI0lGlrGsQ7slSZLUHVO9Ru9dwOOAh5M80LRVVT2+M2UBbadkJ/D/3SqcZBata/uGq+q2JB+l9VgYgK8BC2mFwtGqWjrhoFWLgcXQuut21UuXJEnqvSnN6FXV3Kpaq6rWbZbndijk3cuf7u69EHhtkrWTbEprJu9HTfvrmvbNgLFHvIyFut8nmQM8eiduVT1A6yfcPg+c0IG6JUmSZpypzuiR5NW0whbA+VV19nQXU1VLk1yS5Frg28DVwFW0ZvD+Z1X9OsmZtE7LXgP8jNYpXarqriRfaNpvAS4fN/wpwL7AudNdtyRJ0kw01Qcmf4zW9XGnNE2vp3UK9H0drG1aJXk3sGFVfXgq/YeHh2tkZKTDVUmSJK2+yR6YPNUZvZcD85s7cElyEnAFrbtkZ7xmFnBLWjOBkiRJa4Qpn7ql9TDjO5rlDTtQS8dU1Wt6XYMkSVK3TTXo/SPw4yTn07ob9oXA+ztVlCRJklbfVIPeK4DjgTuBXwLv7eBDkyVJkjQNphr0TqD1AONX0/pJsSuTXFhVn+pYZZIkSVotUwp6VfX9JGO/TLEn8FZavzph0JMkSZqhphT0kvwHrV/GuBS4CNixqn7bycIkSZK0eqb6W7dXA38AtgG2BbZJskHHqpIkSdJqm9IDkx/t3PppsUOBdwNPqar1O1VYrw1lqA7n8F6XIfXEwlrY6xIkSSthtR6YnOQIYHdgB+BWWnfgXjStFUqSJGlaTfWu2w2AT9L62bM/drAeSZIkTZMpXaNXVUdX1WW9DnlJ5iW5PskXklyX5NwkGyTZMsl3kowmuSjJc5KsneSmtGyU5JEkL2zGuSjJM3q5L5IkSZ021ZsxZpJnAp+tqq2Bu4D9gMXAO6pqB1rXD36uqh4GfgZsResZgKPA7knWBzavqp/3pHpJkqQuWZnfup0pbq6qK5vlUWAesAtwepKxPmM3iVxE6+fatgD+N3AYcAFw+UQDJ1kALADYsL9+zleSJOn/048zeg+2LT8MbAzcVVXz217PbT6/iNZNJDsB3wI2AvYALpxo4KpaXFXDVTU8m9kd2wFJkqRu6MegN949wM1JDgBorsnbrvnsMlqzfY9U1QPAlcDheMewJElaAwxC0AM4EHhLkquA64C9AarqQeA24IdNv4uAucA1vShSkiSpm/rqGr2quoXWr3OMvf9428d/Nck6u7ctfxn4cqfqkyRJmkn6Kuh109AOQywc8dcBJElS/xqUU7eSJEkax6AnSZI0oAx6kiRJA8qgJ0mSNKAMepIkSQPKoCdJkjSgDHqSJEkDyqAnSZI0oDrywOQkGwFvqKrPJdkDeHdVvXIaxj0EGK6qI8a1bwqcDawHHFlVE/6WbZKPAveN+0WNCS0ZXcKiLFrdkqUZZ2H5IHBJWlN0akZvI+BtHRp7InsBP62q7ScLeZIkSWuaTgW9jwFbJrkSOBqYk+SMJD9NckqSACT5SJLLk1ybZHFb+/lJ/inJj5L8LMnu4zeQ5BVJLk0yDPwz8PIkVybZIMl9bf32T3Jih/ZTkiRpxupU0Hsf8Iuqmg+8B9ge+DtgK+DpwK5Nv89U1Y5VtQ2wAdB+enedqtqpWe8x55qSvKbZxsuragT4CPCVqppfVfd3aJ8kSZL6SrduxvhRVd1eVY8AVwLzmvY9k1yW5BrgxcDWbet8vfl3tK0/wJ7Ae4FXVNWd01lkkgVJRpKMLGPZdA4tSZLUdd0Keg+2LT8MrJNkFvA5YP+qeh7wBWDWBOs8zGNvGrkJmAs8aznbq7blWZP2Gr9S1eKqGq6q4dnMnupqkiRJM1Kngt69tMLY8owFsN8nmQPsP8WxbwX2BU5OsvUkfX6T5LlJ1gJeM8VxJUmSBkpHHq9SVUuTXJLkWuB+4DcT9LkryReAa4BbgMtXYvwbkhwInJ7kVRN0eR+tx63cBlwLzFn5vZAkSepvqaoV91oDDWWoDufwXpchTTufoydJgyfJaFUNj2/vyIzeIBjaYYiFI/4foiRJ6l/+BJokSdKAMuhJkiQNKIOeJEnSgDLoSZIkDSiDniRJ0oAy6EmSJA0og54kSdKAMuhJkiQNqL54YHKStwLLqurkJIcA51bVkuazLwKfrKqfTOc2l4wuYVEWTeeQUs/4axiStGbqi6BXVce1vT2E1u/XLmk++++9qEmSJGmm6/ip2yTzkvw0yUlJrk5yRpLZSfZKckWSa5Icn2T9pv/Hkvyk6fvxpu2jSd6dZH9gGDglyZVJNkhyfpLhJH+T5J/btntIkk83y29M8qNmnX9Jsnan91uSJKnXunWN3rOBxVW1LXAP8C7gROC1VfU8WjOLf5NkY+A1wNZN339oH6SqzgBGgAOran5V3d/28RnAvm3vXwt8Jclzm+Vdq2o+8DBwYAf2UZIkaUbpVtC7raouaZa/BOwF3FxVP2vaTgJeSCsEPgB8Mcm+wLKpbqCqfgfclOQFSZ5IK1xe0mxrB+DyJFc2758+0RhJFiQZSTKybOqbliRJmpG6dY1eTalT1R+T7EQrjL0OOAJ48Ups5yvAXwM/Bc6sqkoS4KSqev8Utr8YWAwwlKEp1SxJkjRTdWtG78+T7Nwsvx74HjAvyTOatoOAC5LMATasqm8BfwfMn2Cse4G5k2zn68A+zTa+0rT9B7B/kicBJNk4ydNWd4ckSZJmum7N6F0PHJzkX4Abgb8FfgicnmQd4HLgOGBj4Kwks4AA75xgrBOB45LcD+zc/kFV3ZnkJ8BWVfWjpu0nST4EnJtkLeAh4O3ArdO/m5IkSTNHqjp7hjLJPODsqtqmoxuaZkMZqsM5vNdlSNPC5+hJ0mBLMlpVw+Pb++I5er0wtMMQC0f8P0dJktS/Oh70quoWoK9m8yRJkgaBv3UrSZI0oAx6kiRJA8qgJ0mSNKAMepIkSQPKoCdJkjSgDHqSJEkDyqAnSZI0oHxg8iSWjC5hURb1ugxplflrGJKkNWpGL8k+SbbqdR2SJEndsEYFPWAfwKAnSZLWCH1/6jbJh4EDgduA3wOjwJnAZ4FNgWXAYcDGwKuBFyX5ELBfVf2iJ0VLkiR1QV8HvSTDwH7A9rT25ce0gt5i4K1VdWOSvwA+V1UvTvIN4OyqOmOS8RYACwA2ZMNu7IIkSVLH9HXQA3YDzqqq+wGSfBOYBewCnJ5krN/6UxmsqhbTCokMZaimvVpJkqQu6veglwna1gLuqqr53S5GkiRpJun3mzEuBl6VZFaSOcAraF2Td3OSAwDSsl3T/15gbm9KlSRJ6q6+DnpVdTnwDeAq4OvACHA3rZsz3pLkKuA6YO9mldOA9yS5IsmWPShZkiSpa1LV35eiJZlTVfclmQ1cCCyoqh+v7rjDw8M1MjKy+gVKkiR1WJLRqhoe397v1+gBLG4egjwLOGk6Qp4kSdIg6PugV1Vv6HUNkiRJM1FfX6MnSZKkyRn0JEmSBpRBT5IkaUAZ9CRJkgaUQU+SJGlAGfQkSZIGVN8/XqVTlowuYVEW9boM6TEW1sJelyBJ6iNr1IxeknlJru11HZIkSd2wRgU9SZKkNcmMPnWb5MPAgcBtwO+BUeB7wHHAbOAXwJur6s4k8ydp3wE4HlgGXNz9vZAkSeqNGTujl2QY2A/YHtgXGPuh3pOB91bVtsA1wMIVtJ8AHFlVO3erdkmSpJlgxgY9YDfgrKq6v6ruBb4JPA7YqKouaPqcBLwwyYZTbP+35W0wyYIkI0lGlrFs2ndIkiSpm2Zy0Ms0jVFT7VxVi6tquKqGZzN7GjYvSZLUOzM56F0MvCrJrCRzgFcA/wXcmWT3ps9BwAVVdfck7XcBdyfZrWk/sIv1S5Ik9dSMvRmjqi5P8g3gKuBWYAS4GzgYOC7JbOAm4NBmlcnaDwWOT7IMOKeLuyBJktRTqZrymc2uSzKnqu5rwtuFwIKq+nE3tj08PFwjIyPd2JQkSdJqSTJaVcPj22fsjF5jcZKtgFnASd0KeZIkSYNgRge9qnpDr2uQJEnqVzP5ZgxJkiStBoOeJEnSgDLoSZIkDSiDniRJ0oAy6EmSJA0og54kSdKAmtGPV+mlJaNLWJRFvS5DeoyFtbDXJUiS+sjAzuglOSTJZ3pdhyRJUq8MbNCTJEla0/Us6CWZl+SnSU5KcnWSM5LMTrJDkguSjCY5J8lmTf/5SX7Y9D0zyROa9vOTHJPkB0muTbLTBNvaNMnXklzevHbt9v5KkiR1W69n9J4NLK6qbYF7gLcDnwb2r6odgOOBo5q+JwPvbfpeA7RfrPS4qtoFeFuzznifAv5PVe0I7Ad8sRM7I0mSNJP0+maM26rqkmb5S8AHgG2A7yYBWBv4VZINgY2q6oKm70nA6W3jnApQVRcmeXySjcZt5yXAVs2YAI9PMreq7m3vlGQBsABgQzacjv2TJEnqmV4HvRr3/l7guqraub2xCcEySSYAAAm5SURBVHorM87492sBO1fV/csdpGoxsBhgKEPjx5AkSeorvT51++dJxkLd64EfApuOtSVZN8nWVXU3cGeS3Zu+BwEXtI3z2qb/bsDdTf925wJHjL1JMn/6d0WSJGlm6fWM3vXAwUn+BbiR1vV55wDHNrN46wDHANcBBwPHJZkN3AQc2jbOnUl+ADweePME2zkS+GySq5sxLwTe2pldkiRJmhlS1ZszlEnmAWdX1TarOc75wLuramQaynrU8PBwjYxM65CSJGk1PfTQQ9x+++088MADvS6lJ2bNmsXmm2/Ouuuu+5j2JKNVNTy+f69n9CRJkqbs9ttvZ+7cucybN4+2myzXCFXF0qVLuf3229liiy2mtE7PrtGrqltWdzavGWeP6Z7NkyRJM9MDDzzAE5/4xDUu5AEk4YlPfOJKzWb2+mYMSZKklbImhrwxK7vvBj1JkqQZ5JhjjmHZsmXTMpbX6EmSpL61KIumdbyFtXDFnTrsmGOO4Y1vfCOzZ89e7bGc0ZMkSVpJJ598Mttuuy3bbbcdBx10ELfeeit77bUX2267LXvttRe//OUvATjkkEM444wzHl1vzpw5AJx//vnsscce7L///jznOc/hwAMPpKo49thjWbJkCXvuuSd77rnnatfpjJ4kSdJKuO666zjqqKO45JJL2GSTTbjjjjs4+OCDedOb3sTBBx/M8ccfz5FHHsm///u/L3ecK664guuuu46hoSF23XVXLrnkEo488kg++clPct5557HJJpusdq3O6EmSJK2E73//++y///6PBrGNN96YSy+9lDe84Q0AHHTQQVx88cUrHGennXZi8803Z6211mL+/Pnccsst016rM3qTWDK6ZNrP+0urYiZcLyJJ+pOqWuHdr2Ofr7POOjzyyCOPrveHP/zh0T7rr7/+o8trr702f/zjH6e91p7N6CWZl+TaCdq/mGSrZvm+KY41pX6SJEmra6+99uKrX/0qS5cuBeCOO+5gl1124bTTTgPglFNOYbfddgNg3rx5jI6OAnDWWWfx0EMPrXD8uXPncu+9905LrTNuRq+q/nuva5AkSZrM1ltvzQc/+EFe9KIXsfbaa7P99ttz7LHH8uY3v5mjjz6aTTfdlBNOOAGAww47jL333puddtqJvfbai8c97nErHH/BggW87GUvY7PNNuO8885brVp7/Vu33wEuA7YHfga8CfgWzW/XNjN1nwJeCdwP7F1Vv0myBfBlWkH1O8A7q2pOkjnAWcATgHWBD1XVWUn+Hvh9VX2q2fZRwG+q6tjJ6hvKUB3O4R3Yc2nleOpWkv7k+uuv57nPfW6vy+ipib6DyX7rttc3YzwbWFxV2wL3AG8b9/njgB9W1XbAhcBhTfungM9X1Y7Ar9v6PwC8pqqeD+wJfCKtk+T/ChwMkGQt4HXAKZ3ZJUmSpJmh10Hvtqq6pFn+ErDbuM//AJzdLI8C85rlXYFTm+V/a+sf4B+TXA18D3gq8OSqugVYmmR74KXAFVW1dHwxSRYkGUkysozpeSK1JElSr/T6Gr3x543Hv3+o/nRu+WEeW+9E55wPBDYFdqiqh5LcAsxqPvsicAjwFOD4CYupWgwshtap26ntgiRJ0szU6xm9P0+yc7P8emDFD51puYTW6VdohbsxGwK/bULensDT2j47E/grYEfgnFUvWZIk9VKv7i+YCVZ233sd9K4HDm5OtW4MfH6K6/0t8PYkl9MKd2NOAYaTjNAKgD8d+6Cq/gCcB3y1qh6ejuIlSVJ3zZo1i6VLl66RYa+qWLp0KbNmzVpx50bP7rrttuYmjB8DB1TVjSvqPzw8XCMjI50vTJIkTdlDDz3E7bffzgMPPNDrUnpi1qxZbL755qy77rqPaZ/srtteX6PXFc0DmM8GzpxKyJMkSTPTuuuuyxZbbNHrMvrGGhH0quonwNN7XYckSVI39foaPUmSJHWIQU+SJGlArTE3Y6ysJPcCN/S6jjXYJsDve13EGs5j0Hseg97y++89j8HUPa2qNh3fuEZco7eKbpjo7hV1R5IRv//e8hj0nsegt/z+e89jsPo8dStJkjSgDHqSJEkDyqA3ucW9LmAN5/ffex6D3vMY9Jbff+95DFaTN2NIkiQNKGf0JEmSBpRBb5wkf5XkhiQ/T/K+XtczyJLckuSaJFcmGWnaNk7y3SQ3Nv8+oa3/+5vjckOSv+xd5f0pyfFJfpvk2ra2lf6+k+zQHLefJzk2Sbq9L/1qkmPw0ST/2fwdXJnk5W2feQymUZI/S3JekuuTXJfkb5t2/w66ZDnHwL+DTqkqX80LWBv4Ba2fS1sPuArYqtd1DeoLuAXYZFzbPwPva5bfB/xTs7xVczzWB7ZojtPavd6HfnoBLwSeD1y7Ot838CNgZyDAt4GX9Xrf+uU1yTH4KPDuCfp6DKb/+98MeH6zPBf4WfM9+3fQ+2Pg30GHXs7oPdZOwM+r6qaq+gNwGrB3j2ta0+wNnNQsnwTs09Z+WlU9WFU3Az+ndbw0RVV1IXDHuOaV+r6TbAY8vqourdZ/aU9uW0crMMkxmIzHYJpV1a+q6sfN8r3A9cBT8e+ga5ZzDCbjMVhNBr3HeipwW9v721n+/wC1ego4N8lokgVN25Or6lfQ+g8C8KSm3WPTGSv7fT+1WR7frtVzRJKrm1O7Y6cNPQYdlGQesD1wGf4d9MS4YwD+HXSEQe+xJjq/723JnbNrVT0feBnw9iQvXE5fj013TfZ9exym3+eBLYH5wK+ATzTtHoMOSTIH+Brwd1V1z/K6TtDmMZgGExwD/w46xKD3WLcDf9b2fnNgSY9qGXhVtaT597fAmbROxf6mmZKn+fe3TXePTWes7Pd9e7M8vl2rqKp+U1UPV9UjwBf40yUJHoMOSLIurYBxSlV9vWn276CLJjoG/h10jkHvsS4HnplkiyTrAa8DvtHjmgZSksclmTu2DLwUuJbW931w0+1g4Kxm+RvA65Ksn2QL4Jm0LsTV6lmp77s5rXVvkhc0d7i9qW0drYKxgNF4Da2/A/AYTLvm+/pX4Pqq+mTbR/4ddMlkx8C/g85Zp9cFzCRV9cckRwDn0LoD9/iquq7HZQ2qJwNnNnfDrwN8uaq+k+Ry4KtJ3gL8EjgAoKquS/JV4CfAH4G3V9XDvSm9PyU5FdgD2CTJ7cBC4GOs/Pf9N8CJwAa07nT7dhd3o69Ncgz2SDKf1mmnW4DDwWPQIbsCBwHXJLmyafsA/h1002TH4PX+HXSGv4whSZI0oDx1K0mSNKAMepIkSQPKoCdJkjSgDHqSJEkDyqAnSZI0oAx6kiRJA8qgJ0mSNKAMepIkSQPq/wGajqNPbgMxdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot horizontal bar graph\n",
    "term_count_Df.sort_values(by='count').plot.barh(x='words',\n",
    "                      y='count',\n",
    "                      ax=ax,\n",
    "                      color=\"purple\")\n",
    "\n",
    "ax.set_title(\"Top Ten Common Words\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task.6\n",
    "Data formatting for predictive modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task.6.1\n",
    "Join the tokens back to form strings. This will be required for the vectorizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thanks',\n",
       " 'lyft',\n",
       " 'credit',\n",
       " \"can't\",\n",
       " 'use',\n",
       " 'cause',\n",
       " 'offer',\n",
       " 'wheelchair',\n",
       " 'vans',\n",
       " 'pdx',\n",
       " 'disapointed',\n",
       " 'getthanked']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Cleaned_Tweets)\n",
    "Cleaned_Tweets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'father dysfunctional selfish drags kids dysfunction run'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def form_string(Cleaned_Tweets):\n",
    "    String = [\" \".join(Tweet) for Tweet in Cleaned_Tweets]\n",
    "    return String\n",
    "\n",
    "Tweets = form_string(Cleaned_Tweets)\n",
    "Tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cross check If  data is intact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Of Rows In Original Data: 31962\n",
      "No Of Rows In Cleaned Data: 31962\n"
     ]
    }
   ],
   "source": [
    "print(\"No Of Rows In Original Data:\", len(df.label))\n",
    "print(\"No Of Rows In Cleaned Data:\", len(Tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6.2\n",
    "Assign x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Tweets\n",
    "y = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task. 6.3\n",
    "Perform train_test_split using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Size: 23971\n",
      "X_test Size: 7991\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.25\n",
    "random_state=100\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=random_state)\n",
    "\n",
    "print(\"X_train Size:\", len(X_train))\n",
    "print(\"X_test Size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task.7\n",
    "We’ll use TF-IDF values for the terms as a feature to get into a vector space model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task  7.1\n",
    "Import TF-IDF  vectorizer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 7.2\n",
    "Instantiate with a maximum of 5000 terms in your vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 5000\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 7.3\n",
    "Fit and apply on the train set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TFV= vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  7.4\n",
    "Apply On Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_TFV = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_TFV.shape: (23971, 5000)\n",
      "X_test_TFV.shape (7991, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_TFV.shape:\", X_train_TFV.shape)\n",
    "print(\"X_test_TFV.shape\", X_test_TFV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task.8\n",
    "Model building: Ordinary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  8.1\n",
    "Instantiate Logistic Regression from sklearn with default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  8.2\n",
    "Fit into  the train data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(X_train_TFV, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  8.3\n",
    "Make predictions for the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = Model.predict(X_train_TFV)\n",
    "y_test_pred = Model.predict(X_test_TFV)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Task.9\n",
    "Model evaluation: Accuracy, recall, and f_1 score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 9.1\n",
    "Report the accuracy on the train set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Of the Model 95.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy =  round(accuracy_score(y_train, y_train_pred)*100, 2)\n",
    "\n",
    "print(\"Accuracy Of the Model {0}%\" .format(accuracy) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9.2\n",
    "Report the recall on the train set: decent, high, or low.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score- Decent: 69.28%\n",
      "Recall score- Low: 39%\n",
      "Recall score- High: 95.57%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "Decent =  round(metrics.recall_score(y_train, y_train_pred, average='macro')*100, 2)\n",
    "Low = round(metrics.recall_score(y_train, y_train_pred) * 100)\n",
    "High = round(metrics.recall_score(y_train, y_train_pred, average='weighted')*100, 2)\n",
    "    \n",
    "    \n",
    "print(\"Recall score- Decent: {}%\".format(Decent) )\n",
    "print(\"Recall score- Low: {}%\".format(Low) )\n",
    "print(\"Recall score- High: {}%\".format(High ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     22289\n",
      "           1       0.95      0.39      0.55      1682\n",
      "\n",
      "    accuracy                           0.96     23971\n",
      "   macro avg       0.95      0.69      0.76     23971\n",
      "weighted avg       0.96      0.96      0.95     23971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "report = classification_report(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9.3\n",
    "Get the f1 score on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 55.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 Score: {}%\".format(round(f1_score(y_train, y_train_pred)*100,2) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learners Comments\n",
    "\n",
    "It clearly is an indication of data imbalance. The same is evidenced earlier and is represented in Line No.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10\n",
    "Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1\n",
    "Adjust the appropriate class in the LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model  = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11\n",
    "Train again with the adjustment and evaluate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task  11.1 \n",
    "\n",
    "Train the model on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.fit(X_train_TFV, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  11.2\n",
    "\n",
    "Evaluate the predictions on the train set: accuracy, recall, and f_1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.0%\n",
      "\n",
      "Recall score- Decent: 95.88%\n",
      "Recall score- Low: 97.21%\n",
      "Recall score- High: 94.74%\n",
      "\n",
      "F1 Score: 72%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = Model.predict(X_train_TFV)\n",
    "y_test_pred = Model.predict(X_test_TFV)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = round(accuracy_score(y_train, y_train_pred), 2)*100\n",
    "print(\"accuracy: {}%\" .format(accuracy) )\n",
    "print()\n",
    "\n",
    "\n",
    "Decent = round(metrics.recall_score(y_train, y_train_pred, average='macro')*100, 2 )\n",
    "Low = round(metrics.recall_score(y_train, y_train_pred)*100, 2 )\n",
    "High = round(metrics.recall_score(y_train, y_train_pred, average='weighted')*100,2 )\n",
    "\n",
    "\n",
    "print(\"Recall score- Decent: {}%\".format(Decent) )\n",
    "print(\"Recall score- Low: {}%\" .format(Low) )\n",
    "print(\"Recall score- High: {}%\".format(High) )\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"F1 Score: {}%\".format(round(f1_score(y_train, y_train_pred)*100), 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     22289\n",
      "           1       0.57      0.97      0.72      1682\n",
      "\n",
      "    accuracy                           0.95     23971\n",
      "   macro avg       0.79      0.96      0.85     23971\n",
      "weighted avg       0.97      0.95      0.95     23971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task.12\n",
    "Regularization and Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  12.1\n",
    "Import GridSearch and StratifiedKFold because of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 12.2\n",
    "Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'C': [0.001,  0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "                'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n",
    "                'max_iter': [500],\n",
    "              \n",
    "             }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  12.3\n",
    "Use a balanced class weight while instantiating the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task  13\n",
    "Find the parameters with the best recall in cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  13.1\n",
    "Choose ‘recall’ as the metric for scoring.\n",
    "\n",
    "#### Task  13.2\n",
    "Choose a stratified 4 fold cross-validation scheme.\n",
    "\n",
    "#### Task  13.3\n",
    "Fit into  the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 144 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.                nan 0.66942795 0.66942795\n",
      " 0.70271604 0.67061136        nan        nan        nan        nan\n",
      "        nan        nan 0.11118793        nan 0.69856068 0.69856068\n",
      " 0.70509558 0.69856068        nan        nan        nan        nan\n",
      "        nan        nan 0.58144017        nan 0.76753195 0.76753195\n",
      " 0.76812719 0.76753195        nan        nan        nan        nan\n",
      "        nan        nan 0.67715049        nan 0.77110338 0.77110338\n",
      " 0.77110338 0.77110338        nan        nan        nan        nan\n",
      "        nan        nan 0.71757437        nan 0.77644921 0.77644921\n",
      " 0.77704445 0.77644921        nan        nan        nan        nan\n",
      "        nan        nan 0.73184595        nan 0.77704304 0.77704304\n",
      " 0.77763686 0.77704304        nan        nan        nan        nan\n",
      "        nan        nan 0.74135844        nan 0.77704162 0.77704162\n",
      " 0.77704162 0.77704162        nan        nan        nan        nan\n",
      "        nan        nan 0.73719602        nan 0.77763545 0.77763545\n",
      " 0.77822927 0.77763545        nan        nan        nan        nan\n",
      "        nan        nan 0.74254751        nan 0.7788231  0.7788231\n",
      " 0.7788231  0.7788231         nan        nan        nan        nan\n",
      "        nan        nan 0.73898173        nan 0.7764478  0.7764478\n",
      " 0.7764478  0.7764478         nan        nan        nan        nan\n",
      "        nan        nan 0.74135703        nan 0.77822786 0.77822786\n",
      " 0.77822786 0.77822786        nan        nan        nan        nan\n",
      "        nan        nan 0.74314133        nan 0.77525591 0.77525591\n",
      " 0.77525591 0.77525591        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the grid search model\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = Model, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = StratifiedKFold(4), \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 1, \n",
    "                           scoring =  \"recall\",\n",
    "                                           \n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result = grid_search.fit(X_train_TFV, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task  14\n",
    "What are the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 78.0%\n",
      "Best Hyperparameters: {'C': 0.7, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: {}%'.format(round(result.best_score_, 2)*100))\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task  15\n",
    "Predict and evaluate using the best estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  15.1\n",
    "Use the best estimator from the grid search to make predictions on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test_TFV)\n",
    "y_train_pred = grid_search.best_estimator_.predict(X_train_TFV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task  15.2\n",
    "What is the recall on the test set for the toxic comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score- Decent: 95.0%\n",
      "Recall score- Low: 96.0%\n",
      "Recall score- High: 94.0%\n"
     ]
    }
   ],
   "source": [
    "Decent =  round(metrics.recall_score(y_train, y_train_pred, average='macro'),2 )*100\n",
    "Low    =  round(metrics.recall_score(y_train, y_train_pred),2 )*100\n",
    "High   =  round(metrics.recall_score(y_train, y_train_pred, average='weighted'),2 )*100\n",
    "\n",
    "\n",
    "print(\"Recall score- Decent: {}%\". format(Decent))\n",
    "print(\"Recall score- Low: {}%\". format(Low))\n",
    "print(\"Recall score- High: {}%\". format(High))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 15.3\n",
    "What is the f_1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 71.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score: {}%\".format(round(f1_score(y_train, y_train_pred),2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 15.4\n",
    "Full Classificatio Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      7431\n",
      "           1       0.47      0.79      0.59       560\n",
      "\n",
      "    accuracy                           0.92      7991\n",
      "   macro avg       0.73      0.86      0.77      7991\n",
      "weighted avg       0.95      0.92      0.93      7991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print()\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finale accuracy: 92.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = round(accuracy_score(y_test, y_test_pred), 2)*100\n",
    "print(\"Finale accuracy: {}%\" .format(accuracy) )\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learners comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  Have observed the severity of the impact of unbalanced data on the model. Realized the need to  balance the data wherever required.\n",
    "\n",
    "2) I would say the model is excellent with 90% Confidence.\n",
    "\n",
    "3) It still has a scope to experiment with Nl processing libraries and utilising ML models.\n",
    "\n",
    "4) I would like to implement neural networks to build a model for this task. As such I have not built one in tis project as it is outside the scope of the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF THE PROJECT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
