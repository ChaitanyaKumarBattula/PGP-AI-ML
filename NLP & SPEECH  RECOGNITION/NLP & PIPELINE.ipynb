{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE:   PGP [AI&ML]\n",
    "\n",
    "## Learner :  Chaitanya Kumar Battula\n",
    "## Module  : NLP\n",
    "## Topic   : NLP Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Information Extraction Workflow\n",
    "\n",
    "Rawtext(string)  ->\n",
    "Sentence Segmentation (Sentences, List of strings) ->\n",
    "Tokenization (Tokenized Sentences, List of List of strings)  -->\n",
    "Part Of Speech tagging  (Post-tagged Sentences, List of List Of Tuples) -->\n",
    "Entity Recognition (Chunked Sentences, List Of Trees)--> \n",
    "Relation Recognition -->\n",
    "Relations (List Of Tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"\"\" The Golden Retriever is a medium-large gun dog that was bred to retrieve shot waterfowl, such as ducks and upland \n",
    "game birds, during hunting and shooting parties.[3] The name \"retriever\" refers to the breed's ability to retrieve shot game\n",
    "undamaged due to their soft mouth. Golden retrievers have an instinctive love of water, and are easy to train to basic or \n",
    "advanced obedience standards. They are a long-coated breed, with a dense inner coat that provides them with adequate warmth \n",
    "in the outdoors, and an outer coat that lies flat against their bodies and repels water. Golden retrievers are well suited to \n",
    "residency in suburban or country environments.[4] They shed copiously, particularly at the change of seasons, and require \n",
    "fairly regular grooming. The Golden Retriever was originally bred in Scotland in the mid-19th century.[3][5]\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION Golden/NNP)\n",
      "  Retriever/NNP\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  medium-large/JJ\n",
      "  gun/NN\n",
      "  dog/NN\n",
      "  that/WDT\n",
      "  was/VBD\n",
      "  bred/VBN\n",
      "  to/TO\n",
      "  retrieve/VB\n",
      "  shot/NN\n",
      "  waterfowl/NN\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  ducks/NNS\n",
      "  and/CC\n",
      "  upland/JJ\n",
      "  game/NN\n",
      "  birds/NNS\n",
      "  ,/,\n",
      "  during/IN\n",
      "  hunting/VBG\n",
      "  and/CC\n",
      "  shooting/VBG\n",
      "  parties/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/IN\n",
      "  The/DT\n",
      "  name/NN\n",
      "  ``/``\n",
      "  retriever/NN\n",
      "  ''/''\n",
      "  refers/NNS\n",
      "  to/TO\n",
      "  the/DT\n",
      "  breed/NN\n",
      "  's/POS\n",
      "  ability/NN\n",
      "  to/TO\n",
      "  retrieve/VB\n",
      "  shot/JJ\n",
      "  game/NN\n",
      "  undamaged/VBD\n",
      "  due/JJ\n",
      "  to/TO\n",
      "  their/PRP$\n",
      "  soft/JJ\n",
      "  mouth/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (GPE Golden/NNP)\n",
      "  retrievers/NNS\n",
      "  have/VBP\n",
      "  an/DT\n",
      "  instinctive/JJ\n",
      "  love/NN\n",
      "  of/IN\n",
      "  water/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  are/VBP\n",
      "  easy/JJ\n",
      "  to/TO\n",
      "  train/VB\n",
      "  to/TO\n",
      "  basic/VB\n",
      "  or/CC\n",
      "  advanced/JJ\n",
      "  obedience/NN\n",
      "  standards/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  They/PRP\n",
      "  are/VBP\n",
      "  a/DT\n",
      "  long-coated/JJ\n",
      "  breed/NN\n",
      "  ,/,\n",
      "  with/IN\n",
      "  a/DT\n",
      "  dense/NN\n",
      "  inner/NN\n",
      "  coat/NN\n",
      "  that/WDT\n",
      "  provides/VBZ\n",
      "  them/PRP\n",
      "  with/IN\n",
      "  adequate/JJ\n",
      "  warmth/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  outdoors/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  an/DT\n",
      "  outer/NN\n",
      "  coat/NN\n",
      "  that/IN\n",
      "  lies/VBZ\n",
      "  flat/JJ\n",
      "  against/IN\n",
      "  their/PRP$\n",
      "  bodies/NNS\n",
      "  and/CC\n",
      "  repels/NNS\n",
      "  water/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (GPE Golden/JJ)\n",
      "  retrievers/NNS\n",
      "  are/VBP\n",
      "  well/RB\n",
      "  suited/VBN\n",
      "  to/TO\n",
      "  residency/VB\n",
      "  in/IN\n",
      "  suburban/JJ\n",
      "  or/CC\n",
      "  country/NN\n",
      "  environments/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  shed/VBD\n",
      "  copiously/RB\n",
      "  ,/,\n",
      "  particularly/RB\n",
      "  at/IN\n",
      "  the/DT\n",
      "  change/NN\n",
      "  of/IN\n",
      "  seasons/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  require/VBP\n",
      "  fairly/RB\n",
      "  regular/JJ\n",
      "  grooming/NN\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION Golden/NNP)\n",
      "  Retriever/NNP\n",
      "  was/VBD\n",
      "  originally/RB\n",
      "  bred/VBN\n",
      "  in/IN\n",
      "  (GPE Scotland/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  mid-19th/JJ\n",
      "  century/NN\n",
      "  ./.)\n",
      "(S [/RB 3/CD ]/JJ [/$ 5/CD ]/NN)\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words =  nltk.pos_tag(words)\n",
    "        ne_tagged_words = nltk.ne_chunk(tagged_words)\n",
    "        print(ne_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "text = 'My dog bored, and decided to chase our cat. So the cat jumped into my arms'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My dog bored, and decided to chase our cat.', 'So the cat jumped into my arms']\n"
     ]
    }
   ],
   "source": [
    "sent_text = nltk.sent_tokenize(text)\n",
    "print(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'dog', 'bored', ',', 'and', 'decided', 'to', 'chase', 'our', 'cat', '.', 'So', 'the', 'cat', 'jumped', 'into', 'my', 'arms']\n"
     ]
    }
   ],
   "source": [
    "word_text = nltk.word_tokenize(text)\n",
    "print(word_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'dog', 'bored', ',', 'and', 'decided', 'to', 'chase', 'our', 'cat', '.']\n",
      "['So', 'the', 'cat', 'jumped', 'into', 'my', 'arms']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'party', 'was', 'soooo', 'fun', '!', ':D', '#superfun']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "text = 'That party was soooo fun! :D #superfun'\n",
    "\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "tknzr.tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reular Expression\n",
    "\n",
    "\n",
    "Named Entity Recognition\n",
    "\n",
    "Build Noun Phrase Parser using regex\n",
    "\n",
    "named entity practice example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 shows a simple chunk grammar consisting of two rules. The first rule matches an optional determiner or possessive pronoun, zero or more adjectives, then a noun. The second rule matches one or more proper nouns. We also define an example sentence to be chunked [1], and run the chunker on this input [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'The big bird flow over my house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('bird', 'NN'),\n",
       " ('flow', 'NN'),\n",
       " ('over', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('house', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_role = \"NP:{<DT>?<JJ>*<NN>}\"\n",
    "grammar= \"NP: {<DT>?<JJ>*<NN>}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT big/JJ bird/NN)\n",
      "  (NP flow/NN)\n",
      "  over/IN\n",
      "  my/PRP$\n",
      "  (NP house/NN))\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sent) \n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S The/DT big/JJ bird/NN flow/NN over/IN my/PRP$ house/NN)\n"
     ]
    }
   ],
   "source": [
    "# Chunk two consecutive noun\n",
    "\n",
    "grammar = \"NP: {<NN><NN>}  s\"\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sent) \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expression used In Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 'The big bird flow over my house'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('bird', 'NN'),\n",
       " ('flow', 'NN'),\n",
       " ('over', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('house', 'NN')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S The/DT big/JJ bird/NN flow/NN over/IN my/PRP$ house/NN)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reg_rule = \"NP: {<DT><jj>*<NN>}\"\n",
    "\n",
    "cp = nltk.RegexpParser(reg_rule)\n",
    "result = cp.parse(sent) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  big/JJ\n",
      "  (NP bird/NN)\n",
      "  (NP flow/NN)\n",
      "  over/IN\n",
      "  (NP my/PRP$ house/NN))\n"
     ]
    }
   ],
   "source": [
    "ex = 'Her big bird flow over my house'\n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "\n",
    "\n",
    "\n",
    "reg_rule = \"NP: {<DT|PRP\\$>?<jj>*<NN>}\"\n",
    "\n",
    "cp = nltk.RegexpParser(reg_rule)\n",
    "result = cp.parse(sent) \n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Sammie/NNP)\n",
      "  gave/VBD\n",
      "  me/PRP\n",
      "  (NP her/PRP$ favourite/JJ book/NN))\n"
     ]
    }
   ],
   "source": [
    "ex = 'Sammie gave me her favourite book'\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "sent = preprocess(ex)\n",
    "\n",
    "\n",
    "reg_rule = r\"\"\"\n",
    "           NP: {<DT|PRP\\$>?<JJ>*<NN>}\n",
    "               {<NNP>+}\n",
    "\n",
    "           \"\"\"\n",
    "cp = nltk.RegexpParser(reg_rule)\n",
    "result = cp.parse(sent) \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
