{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Password Strength Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  first we need to read the data from data.csv file, therefore we need to import the basic python library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\nSkipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\nSkipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\nSkipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\nSkipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\nSkipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\nSkipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\nSkipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\nSkipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\nSkipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\nSkipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\nSkipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\nSkipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\nSkipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\nSkipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\nSkipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\nSkipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\nSkipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\nSkipping line 183603: expected 2 fields, saw 5\\nSkipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\nSkipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\nSkipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\nSkipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\nSkipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\nSkipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\nSkipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\nSkipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\nSkipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\nSkipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\nSkipping line 308926: expected 2 fields, saw 5\\nSkipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\nSkipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\nSkipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\nSkipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\nSkipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\nSkipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\nSkipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\nSkipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\nSkipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\nSkipping line 419423: expected 2 fields, saw 5\\nSkipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\nSkipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\nSkipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\nSkipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\nSkipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\nSkipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\nSkipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\nSkipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\nSkipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\nSkipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\nSkipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\nSkipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\nSkipping line 544954: expected 2 fields, saw 5\\nSkipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\nSkipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\nSkipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\nSkipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\nSkipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\nSkipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\nSkipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\nSkipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\nSkipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\nSkipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\nSkipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READING THE DATASETS\n",
    "data=pd.read_csv('../DataSets/password-strength.csv',error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['strength'].unique() #Checking the unique strength present in dataset, 0-poor, 1 for average, 2 for best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    1\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECKING ALL THE MISSING VALUES IN DATASET AND DROPPOING THEM ALL\n",
    "data.isna().sum() # checking is there any Nan value in data, here only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       password  strength\n",
       "367579      NaN         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['password'].isnull()] # finding the position where it is Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True) # dropping that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    0\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() # after dropping , checking if there is not any Nan value, here 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='strength', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['strength']) # checking the freq of each category of strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_tuple=np.array(data) # now we create an array containing all the data of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kino3434', 1],\n",
       "       ['visi7k1yr', 1],\n",
       "       ...,\n",
       "       ['184520socram', 1],\n",
       "       ['marken22a', 1],\n",
       "       ['fxx4pw4g', 1]], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password_tuple # printing that array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kzde5577', 1],\n",
       "       ['kzde5577', 1],\n",
       "       ...,\n",
       "       ['kleber3090', 1],\n",
       "       ['scstc521', 1],\n",
       "       ['kukkik1992', 1]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the data to create the robustness\n",
    "import random # therefore importing random\n",
    "random.shuffle(password_tuple) # using shuffle function make the array shuffled\n",
    "password_tuple # printing the array after shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for list comprehension\n",
    "# first column is put in x list\n",
    "# ans 2nd column in y list\n",
    "x=[labels[0] for labels in password_tuple]\n",
    "y=[labels[1] for labels in password_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kzde5577',\n",
       " 'kzde5577',\n",
       " 'kzde5577',\n",
       " 'kino3434',\n",
       " 'kzde5577',\n",
       " 'megzy123',\n",
       " 'u6c8vhow',\n",
       " 'visi7k1yr',\n",
       " 'megzy123',\n",
       " 'u6c8vhow',\n",
       " 'kzde5577',\n",
       " 'asv5o9yu',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'v1118714',\n",
       " 'visi7k1yr',\n",
       " 'kzde5577',\n",
       " '612035180tok',\n",
       " 'megzy123',\n",
       " 'as326159',\n",
       " '612035180tok',\n",
       " 'lamborghin1',\n",
       " 'megzy123',\n",
       " 'kzde5577',\n",
       " 'idofo673',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'czuodhj972',\n",
       " 'cigicigi123',\n",
       " 'idofo673',\n",
       " 'jerusalem393',\n",
       " 'v1118714',\n",
       " 'schalke04',\n",
       " 'kino3434',\n",
       " 'lamborghin1',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'memjan123',\n",
       " 'lsdlsd1',\n",
       " 'lamborghin1',\n",
       " 'lamborghin1',\n",
       " '612035180tok',\n",
       " 'jerusalem393',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'memjan123',\n",
       " 'asgaliu11',\n",
       " 'as326159',\n",
       " 'asgaliu11',\n",
       " 'visi7k1yr',\n",
       " 'go7kew7a2po',\n",
       " 'visi7k1yr',\n",
       " 'u6c8vhow',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'idofo673',\n",
       " 'schalke04',\n",
       " 'cigicigi123',\n",
       " 'yqugu927',\n",
       " 'fahad123',\n",
       " 'prisonbreak1',\n",
       " 'sbl571017',\n",
       " 'kzde5577',\n",
       " 'hpqkoxsn5',\n",
       " 'czuodhj972',\n",
       " 'yitbos77',\n",
       " 'openup12',\n",
       " 'fk9qi21m',\n",
       " 'czuodhj972',\n",
       " 'asv5o9yu',\n",
       " '52558000aaa',\n",
       " '6975038lp',\n",
       " 'kswa2mrv',\n",
       " 'idofo673',\n",
       " 'fahad123',\n",
       " 'faranumar91',\n",
       " 'kzde5577',\n",
       " 'd04m11',\n",
       " 'go7kew7a2po',\n",
       " 'schalke04',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'snolyuj04',\n",
       " 'lsdlsd1',\n",
       " 'jerusalem393',\n",
       " 'olmaz.',\n",
       " 'klara-tershina3H',\n",
       " 'olmaz.',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'exitos2009',\n",
       " 'lsdlsd1',\n",
       " 'd04m11',\n",
       " 'gaymaids1',\n",
       " 'c3h8bkzr',\n",
       " 'juliel009',\n",
       " 'jytifok873',\n",
       " '0169395484a',\n",
       " 'gdfn76',\n",
       " 'fk9qi21m',\n",
       " 'sbl571017',\n",
       " 'olmaz.',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'jalingo1',\n",
       " 'hodygid757',\n",
       " 'snolyuj04',\n",
       " 'fk9qi21m',\n",
       " 'gdfn76',\n",
       " 'czuodhj972',\n",
       " 'universe2908',\n",
       " 'sknq7m0',\n",
       " 'asgaliu11',\n",
       " 'il0vey0u',\n",
       " 'elonex24',\n",
       " 'gkrqjs6',\n",
       " 'k9b8cz6aj2',\n",
       " 'juliana19',\n",
       " 'jonothepoop1',\n",
       " 'universe2908',\n",
       " 'kjkjkj1',\n",
       " '52558000aaa',\n",
       " 'as326159',\n",
       " '52558000aaa',\n",
       " 'schalke04',\n",
       " '929865yt',\n",
       " 'exitos2009',\n",
       " 'moken7',\n",
       " 'openup12',\n",
       " 'obstacle25',\n",
       " '123maxbala',\n",
       " 'universe2908',\n",
       " 'elonex24',\n",
       " 'd04m11',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'hodygid757',\n",
       " 'cesarmaio1',\n",
       " 'icap12',\n",
       " 'ikanez886',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'faranumar91',\n",
       " 'asv5o9yu',\n",
       " 'pato221182',\n",
       " 'zoobike04',\n",
       " '6975038lp',\n",
       " 'openup12',\n",
       " '2akira2',\n",
       " 'gdfn76',\n",
       " '929865yt',\n",
       " 'rogyh820',\n",
       " 's4m2dx9e6',\n",
       " 'idofo673',\n",
       " 'w9209640',\n",
       " 'elonex24',\n",
       " 'lsdlsd1',\n",
       " 'ns2b0727',\n",
       " 'jalingo1',\n",
       " 'warriors08',\n",
       " 'oekojWyH120063',\n",
       " '2010server',\n",
       " 'lamborghin1',\n",
       " 'c3h8bkzr',\n",
       " '838188linh',\n",
       " '123477889a',\n",
       " 'cesarmaio1',\n",
       " 'go7kew7a2po',\n",
       " 'asgaliu11',\n",
       " '929865yt',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " '123477889a',\n",
       " 'yu4cmn',\n",
       " 'www32223222',\n",
       " 'rntprns7',\n",
       " 'ns2b0727',\n",
       " 'il0vey0u',\n",
       " 'kinga22',\n",
       " 'ok>bdk',\n",
       " 'teemteem97',\n",
       " 'olmaz.',\n",
       " 'asv5o9yu',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'ginger972',\n",
       " 'asgaliu11',\n",
       " 'bozoxik602',\n",
       " 'lsdlsd1',\n",
       " 'ok>bdk',\n",
       " 'hayhayq2',\n",
       " '2010server',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " '5gzj5uf',\n",
       " 'visi7k1yr',\n",
       " '2yz4ewwg',\n",
       " 'ejeko677',\n",
       " '123477889a',\n",
       " 'elonex24',\n",
       " 'snolyuj04',\n",
       " 'yitbos77',\n",
       " 'openup12',\n",
       " 'a2531106',\n",
       " 'a0972986650',\n",
       " 'jonothepoop1',\n",
       " 'nello11',\n",
       " 'potatobus150',\n",
       " 'sknq7m0',\n",
       " 'rntprns7',\n",
       " 'sarahi1628',\n",
       " '20010509wang',\n",
       " '0870330135a',\n",
       " 'faranumar91',\n",
       " 'jytifok873',\n",
       " 'patri1973',\n",
       " 'as326159',\n",
       " '2021848709.',\n",
       " 'IjUcOtYqAwel725',\n",
       " 'xyws951753',\n",
       " 'hpqkoxsn5',\n",
       " 'ekufite742',\n",
       " 'trabajonet9',\n",
       " 'sbl571017',\n",
       " 'lamborghin1',\n",
       " 'tin030201',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'tin030201',\n",
       " 'kayal123',\n",
       " '20Dgw7TQ0OQVdly7',\n",
       " '6975038lp',\n",
       " 'warriors08',\n",
       " '746xitEGiqObog',\n",
       " 'X9WVojjE4MgVAIiR',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'tamanagung6',\n",
       " 'igejasy712',\n",
       " 'calcifer32',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'tia150979',\n",
       " 'alchimie79',\n",
       " 'damyvo114',\n",
       " 'as326159',\n",
       " 'nicolas05',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'ekufite742',\n",
       " 'yut0838828185',\n",
       " 'gandhi8513',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'kayal123',\n",
       " 'barboza221294',\n",
       " 'sarahi1628',\n",
       " 'prisonbreak1',\n",
       " '26522876p',\n",
       " 'p@sslng2diword',\n",
       " 'snolyuj04',\n",
       " 'fk9qi21m',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " '64959rodro',\n",
       " 'wycinu436',\n",
       " 'caramelo9',\n",
       " 'sbaUsoTA1OAzuevI',\n",
       " '159951josh',\n",
       " 'ekufite742',\n",
       " 'tomas7896',\n",
       " 'gill02',\n",
       " 'w9209640',\n",
       " '6975038lp',\n",
       " '4fqa52vecr',\n",
       " '3vszncp4',\n",
       " 'w9209640',\n",
       " 'atigi839',\n",
       " 'bozoxik602',\n",
       " 'wisal1234',\n",
       " '3vszncp4',\n",
       " 'juliana19',\n",
       " 'zoobike04',\n",
       " 'v1118714',\n",
       " 'il0vey0u',\n",
       " 'nK0yKXTU0NQHZE2e',\n",
       " 'calcifer32',\n",
       " '7942vikas',\n",
       " 'aquhih220',\n",
       " 'k1k2k3k4k5k6',\n",
       " 's4m2dx9e6',\n",
       " 'snolyuj04',\n",
       " '5gzj5uf',\n",
       " 'faranumar91',\n",
       " 'lsdlsd1',\n",
       " 'jalingo1',\n",
       " 'rntprns7',\n",
       " 'sasuke4',\n",
       " 'patty94',\n",
       " 'jonothepoop1',\n",
       " 'witek1709',\n",
       " 'isqizkg1',\n",
       " 'u6c8vhow',\n",
       " 'kry1z9',\n",
       " 'nicolas05',\n",
       " 'barboza221294',\n",
       " '2fakjv',\n",
       " 'fahad123',\n",
       " 'as326159',\n",
       " 'barra23',\n",
       " 'marita1',\n",
       " '123net123',\n",
       " 'p2share',\n",
       " '2010server',\n",
       " 'a0972986650',\n",
       " '26522876p',\n",
       " '2fakjv',\n",
       " 'sbl571017',\n",
       " 'oekojWyH120063',\n",
       " 'x8512514',\n",
       " 'wisal1234',\n",
       " 'witek1709',\n",
       " 'q0pv0fk',\n",
       " 'asv5o9yu',\n",
       " 'caramelo9',\n",
       " 'mustang337',\n",
       " 'tomas7896',\n",
       " 'sydney213',\n",
       " 'y0unus',\n",
       " 'AS0130066',\n",
       " 'clave08',\n",
       " 'xiau5ff',\n",
       " 'mickael12',\n",
       " '3vszncp4',\n",
       " 'ginger972',\n",
       " 'aquhih220',\n",
       " 'bgrvl80',\n",
       " 'kayal123',\n",
       " '631ihOZogELoVap',\n",
       " 'xanyrum650',\n",
       " 'tia150979',\n",
       " 'caramelo9',\n",
       " 'gdfn76',\n",
       " 'demon10',\n",
       " 'g067057895',\n",
       " 'cigicigi123',\n",
       " 'kuntz80',\n",
       " 'bencike7',\n",
       " 'il0vey0u',\n",
       " 'mario489800',\n",
       " 'metopelo1623',\n",
       " 'bugatti01',\n",
       " 'trabajonet9',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'omakiva153',\n",
       " 'sofietou74',\n",
       " 'sebo82',\n",
       " 'franczuk33',\n",
       " 'czuodhj972',\n",
       " 'w9209640',\n",
       " 'tucagu356',\n",
       " 'kayal123',\n",
       " 'acetita478',\n",
       " 'patty94',\n",
       " 'witek1709',\n",
       " 'kayal123',\n",
       " 'juliel009',\n",
       " 'examy624',\n",
       " 'mathilde54550',\n",
       " 'snolyuj04',\n",
       " '0870330135a',\n",
       " 'mario489800',\n",
       " 'd04m11',\n",
       " 'alchimie79',\n",
       " 'acetita478',\n",
       " 'gkrqjs6',\n",
       " 'clave08',\n",
       " 'demon10',\n",
       " 'p2share',\n",
       " 'ass359',\n",
       " 'barra23',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'deryxi704',\n",
       " 'bellsuki1',\n",
       " 'ts34a3fodh3i',\n",
       " 'nello11',\n",
       " 'virush1n1',\n",
       " 'ram@!sita15392',\n",
       " 'matiz4533',\n",
       " 'deryxi704',\n",
       " 'iwaguh884',\n",
       " 'ass359',\n",
       " '283671gus',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " '612035180tok',\n",
       " '2yz4ewwg',\n",
       " 'openup12',\n",
       " 'woon12',\n",
       " 'ts34a3fodh3i',\n",
       " 'g3rappa',\n",
       " '52558000aaa',\n",
       " 'iwaguh884',\n",
       " '2fakjv',\n",
       " 'sbl571017',\n",
       " 'nLIGyhTU1NQTAp6u',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'autan88',\n",
       " 'rogyh820',\n",
       " 'clyioqzgw42',\n",
       " '3y6iwef2g6',\n",
       " 'polo2014',\n",
       " 'd4xQ3LjUwMQFVCYQ',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'a2531106',\n",
       " 'xiau5ff',\n",
       " 't8IkFRDIxMAFV2JW',\n",
       " 'hasan18',\n",
       " 'iwaguh884',\n",
       " '159951josh',\n",
       " 'ikanez886',\n",
       " 'intel1',\n",
       " 'Staterkom20081993',\n",
       " '215466kenyi',\n",
       " 'gerardway1',\n",
       " 'a2531106',\n",
       " 'mmm23mm',\n",
       " 'nello11',\n",
       " 'tamanagung6',\n",
       " 'mazdarx7',\n",
       " 'a0972986650',\n",
       " 'lymuvop730',\n",
       " 'ryjypes139',\n",
       " 'Staterkom20081993',\n",
       " 'metopelo1623',\n",
       " 'sanjaime1',\n",
       " 'franczuk33',\n",
       " 'krishna2',\n",
       " 'sanjaime1',\n",
       " 'pazzini24',\n",
       " 'teste10',\n",
       " 'josue12',\n",
       " 'djngeyut2707',\n",
       " 'koabcswzt3',\n",
       " 'mustang337',\n",
       " 'icap12',\n",
       " 'sbaUsoTA1OAzuevI',\n",
       " '1qa2ws3ed4rf',\n",
       " 'cdann123',\n",
       " 'ikanez886',\n",
       " 'kjkjkj1',\n",
       " 'marita1',\n",
       " 'c3h8bkzr',\n",
       " 'rntprns7',\n",
       " '52558000aaa',\n",
       " 'clumsy0619',\n",
       " 'ginger972',\n",
       " 'barra23',\n",
       " '6yy6yy',\n",
       " 'kitty555',\n",
       " 'tomas7896',\n",
       " 'xyws951753',\n",
       " 'yk530mg8',\n",
       " 'kayal123',\n",
       " '20Dgw7TQ0OQVdly7',\n",
       " 'QWERTY0011',\n",
       " 'djngeyut2707',\n",
       " 'witek1709',\n",
       " 'czuodhj972',\n",
       " 'obstacle25',\n",
       " 'pekai2004',\n",
       " 'jonothepoop1',\n",
       " '19821010a',\n",
       " 'seng987321',\n",
       " 'lymuvop730',\n",
       " 'YADHJIGSAWS11',\n",
       " 'nicolas05',\n",
       " 'xf6385494',\n",
       " 'examy624',\n",
       " 'djngeyut2707',\n",
       " 'autan88',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'yllime123',\n",
       " '929865yt',\n",
       " 'taurofive16',\n",
       " 'a03242241431a',\n",
       " 'krishna2',\n",
       " 'may112001',\n",
       " 'caramelo9',\n",
       " 'hisnipes1',\n",
       " 'ginger972',\n",
       " 'ebacuro434',\n",
       " '215466kenyi',\n",
       " 'cesarmaio1',\n",
       " 'p@sslng2diword',\n",
       " '9950twofour0',\n",
       " 'zidadoh258',\n",
       " 'oatcake87',\n",
       " 'znbl5tj1',\n",
       " 'xyws951753',\n",
       " '238wofutUtIGyf',\n",
       " 'matiz4533',\n",
       " '4165000yakub',\n",
       " 'pablo321159',\n",
       " 'djngeyut2707',\n",
       " '52558000aaa',\n",
       " 'abizar08',\n",
       " 'examy624',\n",
       " 'k9b8cz6aj2',\n",
       " 'idofo673',\n",
       " 'iwaguh884',\n",
       " 'kXzWOozU2MQ1Jv1h',\n",
       " '16731673ir',\n",
       " 'fnmsdha476',\n",
       " 'ixehawojEPe418',\n",
       " 'pikey231',\n",
       " 'jytifok873',\n",
       " 'krumbul123',\n",
       " 'servbot88',\n",
       " 'sysoja794',\n",
       " 'jerusalem393',\n",
       " 'juliana19',\n",
       " 'sasuke4',\n",
       " '1ngaymuadong',\n",
       " '2GnTStTE4Mw4MTwv',\n",
       " 'hasan18',\n",
       " 'g3rappa',\n",
       " '1972vishara',\n",
       " 'zoobike04',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'synyxyr723',\n",
       " 'fahad123',\n",
       " 'cristiano7',\n",
       " 'juliel009',\n",
       " 'zjl0kx03',\n",
       " '4lgYVfzk1MwuzHcn',\n",
       " '4TXr5KDYxNQVTo4g',\n",
       " 'gerardway1',\n",
       " 'hisnipes1',\n",
       " 'byeypb2',\n",
       " 'rLLh4WDQ2OAWbDO5',\n",
       " 'ixehawojEPe418',\n",
       " 'faranumar91',\n",
       " 'kenyu001',\n",
       " '2021848709.',\n",
       " 'pekai2004',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " 'www32223222',\n",
       " 'kabrito1',\n",
       " 'nhfdff2512',\n",
       " 'khaled12',\n",
       " '159951josh',\n",
       " '05bumd',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'wisal1234',\n",
       " '1991vikash',\n",
       " 'zedika521',\n",
       " 'acetita478',\n",
       " 'njmania114',\n",
       " '9950twofour0',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'woaini0',\n",
       " 'kdl9cl53',\n",
       " '2akira2',\n",
       " 'GGmm26120904..',\n",
       " 'khaled12',\n",
       " 'tamanagung6',\n",
       " 'xlxlxl777',\n",
       " 'mohantra1',\n",
       " 'oatcake87',\n",
       " 's4m2dx9e6',\n",
       " 'www32223222',\n",
       " 'cdann123',\n",
       " 'JEQuloqOFUd102',\n",
       " 'Oshity07142014',\n",
       " 'mayur@8netinfotech',\n",
       " 'g067057895',\n",
       " 'graciela2',\n",
       " 'marita1',\n",
       " 'seller1',\n",
       " 'olyucskw52',\n",
       " 'kyxvufl37',\n",
       " 'Iamthelegend1!',\n",
       " 'yllime123',\n",
       " 'uxyloga692',\n",
       " 'ok>bdk',\n",
       " 'go7kew7a2po',\n",
       " 'sbaUsoTA1OAzuevI',\n",
       " 'ebacuro434',\n",
       " 'upomel180',\n",
       " 'a0972986650',\n",
       " 'znbl5tj1',\n",
       " 'yllime123',\n",
       " 'znbl5tj1',\n",
       " 'bc5e4vca',\n",
       " 'idofo673',\n",
       " 'bc5e4vca',\n",
       " 'fk9qi21m',\n",
       " '23deagosto',\n",
       " 'graciela2',\n",
       " 'mmm23mm',\n",
       " 'UF1Z2WjE5Mg26R1K',\n",
       " '2GnTStTE4Mw4MTwv',\n",
       " 'mega0109',\n",
       " 'ts34a3fodh3i',\n",
       " '1234159hero',\n",
       " 'yogesh143',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " 'okn9zp9o',\n",
       " '612035180tok',\n",
       " 'YADHJIGSAWS11',\n",
       " '12345yolanda',\n",
       " 's9830950044',\n",
       " 'DRAGON25',\n",
       " 'nello11',\n",
       " 'Herzberg@ABBOTT33656888commerce',\n",
       " 'uoaef06gfqeb',\n",
       " 'a0972986650',\n",
       " 'hisnipes1',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'ayles2266',\n",
       " 'bellsuki1',\n",
       " 'puegwajy416',\n",
       " 'kyxvufl37',\n",
       " 'mario489800',\n",
       " 'killer5',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'lugerp08',\n",
       " '6975038lp',\n",
       " '64whbrb351',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'bellsuki1',\n",
       " 'ginger972',\n",
       " 'robot425',\n",
       " 'sono11',\n",
       " 'terrassa6',\n",
       " '72o0yzekib4',\n",
       " 'viri13',\n",
       " '631ihOZogELoVap',\n",
       " 'trabajonet9',\n",
       " 'synyxyr723',\n",
       " 'nokia6020',\n",
       " 'hayhayq2',\n",
       " 'woogee04',\n",
       " 'cerner09',\n",
       " 'rqmswof2llb0',\n",
       " 'pazzini24',\n",
       " 'kP82iqDMxNgBMxBP',\n",
       " 'pazzini24',\n",
       " 'kry1z9',\n",
       " 'aqyba894',\n",
       " '600eretz',\n",
       " 'oscar69',\n",
       " 'visi7k1yr',\n",
       " 'synyxyr723',\n",
       " 'wbtdrieus345',\n",
       " 'as326159',\n",
       " 'nello11',\n",
       " '3y6iwef2g6',\n",
       " '0VKWoODkwOAc0pZK',\n",
       " '7l1hu1xa',\n",
       " 'we34dar88',\n",
       " 'fnmsdha476',\n",
       " 'pilatyj280',\n",
       " 'snolyuj04',\n",
       " '238wofutUtIGyf',\n",
       " 'd04m11',\n",
       " 'viri13',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'ypodahe201',\n",
       " '4fqa52vecr',\n",
       " 'zidadoh258',\n",
       " 'change201',\n",
       " 'avanakit72',\n",
       " 'buqodym199',\n",
       " 'raykuaz32',\n",
       " 'ekufite742',\n",
       " 'aslpls2009',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " 'matiofox08',\n",
       " 'yzxwvgbdu503',\n",
       " 'uxyloga692',\n",
       " 'gozv3e5',\n",
       " 'zjl0kx03',\n",
       " 'qn5xpg3k00',\n",
       " 'bellsuki1',\n",
       " 'x0004534',\n",
       " 'mayur@8netinfotech',\n",
       " 'yuri110995',\n",
       " 'pxjwmeqyn5',\n",
       " 'Staterkom20081993',\n",
       " 'm4r4hne',\n",
       " 'megzy123',\n",
       " 'just1n0k',\n",
       " '19840510kkk1',\n",
       " 'elonex24',\n",
       " 'osimeytju12',\n",
       " 'ahibyg892',\n",
       " 'ikanez886',\n",
       " 'zedika521',\n",
       " 'x57669',\n",
       " 'edcmki90',\n",
       " 'clumsy0619',\n",
       " 'kry1z9',\n",
       " 'zu20081965',\n",
       " 'QWERTY0011',\n",
       " 'djda1203zj',\n",
       " 'exitos2009',\n",
       " 'sasuke4',\n",
       " 'hamqrc6',\n",
       " 'tin030201',\n",
       " 'prisonbreak1',\n",
       " 'tim80327',\n",
       " 'ydd45ee',\n",
       " 'hlQ8gDTExMQWkeda',\n",
       " 'may112001',\n",
       " 'vestax25',\n",
       " 'Jovan13lovekenthjusvan4ever',\n",
       " 'xve33ea',\n",
       " 'terrassa6',\n",
       " 'mickael12',\n",
       " 'bang6k',\n",
       " 'kjkjkj1',\n",
       " 'asdasdf1',\n",
       " 'poseidon2011',\n",
       " 'n501iomf',\n",
       " 'spl51190595',\n",
       " 'ok>bdk',\n",
       " 'zidadoh258',\n",
       " '6975038lp',\n",
       " '123nicole',\n",
       " 'zendegi2me',\n",
       " 'pekai2004',\n",
       " '090mca090',\n",
       " 'roxana1993',\n",
       " 'balamuc123',\n",
       " 'nhiannei040',\n",
       " 'hosna1368',\n",
       " 'macias2010',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'zcsntdmhe098',\n",
       " 'moken7',\n",
       " 'universe2908',\n",
       " 'u6c8vhow',\n",
       " 'topgan22',\n",
       " 'aslanmarco007',\n",
       " 'tomas7896',\n",
       " 'pablo321159',\n",
       " 'gracimir87',\n",
       " 'lollies1989',\n",
       " 'zidadoh258',\n",
       " 'overlord3127',\n",
       " 'luthien123',\n",
       " 'jcav26',\n",
       " '159951josh',\n",
       " 'umetic21',\n",
       " 'wibi182d',\n",
       " 'ejeko677',\n",
       " 'QWERTY0011',\n",
       " 'bghuyku37',\n",
       " 'bencike7',\n",
       " 'fudijep286',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'qopybuxi2',\n",
       " 'mustang337',\n",
       " 'fk9qi21m',\n",
       " 'abizar08',\n",
       " 'ebogel225',\n",
       " '0123one47',\n",
       " 'memjan123',\n",
       " 'o7ShLdTM0NAQRI7E',\n",
       " 'sebo82',\n",
       " 'daaxvie1',\n",
       " 'josef0867',\n",
       " '1w2e3s4l5e6y',\n",
       " 'pardalgg5',\n",
       " 'sanki1',\n",
       " 'lsdlsd1',\n",
       " 'afs34214',\n",
       " 'yogesh143',\n",
       " 'seller1',\n",
       " '101010hadis',\n",
       " '8g8x2su3',\n",
       " 'visi7k1yr',\n",
       " 'franczuk33',\n",
       " '746xitEGiqObog',\n",
       " '147963asd',\n",
       " 'novelia21',\n",
       " '1ug2UKzQyMQBsleD',\n",
       " 'uziwocy148',\n",
       " 'faranumar91',\n",
       " 'lymuvop730',\n",
       " 'igejasy712',\n",
       " 'enziitoo1234',\n",
       " 'plumilla1',\n",
       " 'osimeytju12',\n",
       " 'denise18',\n",
       " 'tia150979',\n",
       " 'gutergut599',\n",
       " 'zedika521',\n",
       " '7l1hu1xa',\n",
       " 'sqsn7a9',\n",
       " 'L2i2ZwTg1MQajeBm',\n",
       " 'wasanun13',\n",
       " 'mdaffandi74',\n",
       " '1w2e3s4l5e6y',\n",
       " 'pilatyj280',\n",
       " 'ekufite742',\n",
       " 'megdam55',\n",
       " '2652033abc',\n",
       " 'grazi0201',\n",
       " 'patata91',\n",
       " 'wuzyci421',\n",
       " 'iacool99',\n",
       " 'ldteugao6',\n",
       " 'sofietou74',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'zendegi2me',\n",
       " 'xp;ysmybst',\n",
       " 'kinga22',\n",
       " '241189dumai',\n",
       " 'satrjcrj6',\n",
       " 'ilunia20',\n",
       " '600eretz',\n",
       " 'u6c8vhow',\n",
       " 'tiga33',\n",
       " 'bozoxik602',\n",
       " 'urban1',\n",
       " 'amandine666',\n",
       " 'azizi120583',\n",
       " 'lofebop480',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'gdfn76',\n",
       " 'pxjwmeqyn5',\n",
       " 'qwekl12',\n",
       " '2010server',\n",
       " '1ug2UKzQyMQBsleD',\n",
       " '238wofutUtIGyf',\n",
       " 'designer1206',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'teste10',\n",
       " 'tPGMkBjkyMg3hGzu',\n",
       " 'olumide1',\n",
       " 'igejasy712',\n",
       " 'acgyj188',\n",
       " 'trust123',\n",
       " 'Zdyf0kjMzNQycqPx',\n",
       " 'zoblin80',\n",
       " 'legna13',\n",
       " 'xzeyfbi495',\n",
       " 'xiau5ff',\n",
       " '1qa2ws3ed4rf',\n",
       " 'prisonbreak1',\n",
       " 'midgeman8505',\n",
       " 'yhigkenj5',\n",
       " 'w1e2s3l4',\n",
       " 'ufoduvo540',\n",
       " 'aquhih220',\n",
       " 'galoucura1',\n",
       " '631ihOZogELoVap',\n",
       " 'uzifyc502',\n",
       " 'hola45',\n",
       " 'pap0spep0s',\n",
       " '72o0yzekib4',\n",
       " '029992546sj',\n",
       " 'cristiano7',\n",
       " '72o0yzekib4',\n",
       " 'purpledog1992',\n",
       " 'upyjlneg80',\n",
       " 'twil8x0',\n",
       " 'goony01',\n",
       " 'hylefup708',\n",
       " 'clave08',\n",
       " 'ryjypes139',\n",
       " 'jbtcnd6',\n",
       " 'patty94',\n",
       " 'hosna1368',\n",
       " 'gerardway1',\n",
       " 'kry1z9',\n",
       " 'cdann123',\n",
       " 'j03l4ytr1',\n",
       " 'krumbul123',\n",
       " 'g3rappa',\n",
       " 'lqksuym982',\n",
       " 'pizxmwaos537',\n",
       " 'korea2010',\n",
       " 'afan520307',\n",
       " 'pr0f1s10',\n",
       " 'planes123',\n",
       " 'cyborged69',\n",
       " 'koulapic33',\n",
       " 'gill02',\n",
       " 'orysex325',\n",
       " 'orejuby808',\n",
       " 'cerner09',\n",
       " 'aqyba894',\n",
       " 'kabrito1',\n",
       " 'j09000',\n",
       " '000martin',\n",
       " 'bgrvl80',\n",
       " 'jerusalem393',\n",
       " 'sandra0547',\n",
       " 'bozoxik602',\n",
       " '090mca090',\n",
       " 'franczuk33',\n",
       " '2863e00016',\n",
       " 'killer5',\n",
       " 'sydney213',\n",
       " 'koulapic33',\n",
       " 'zeitgeist1',\n",
       " 'hylefup708',\n",
       " 'samael666',\n",
       " '3clrcaevu7',\n",
       " 'lollies1989',\n",
       " 'Ju6BIMTU0MwYXtL4',\n",
       " 'sd6x9s3s',\n",
       " 'bghuyku37',\n",
       " 'damyvo114',\n",
       " 'peter04',\n",
       " 'lrhxmevb620',\n",
       " 'walterivl13',\n",
       " 'nndcvf1',\n",
       " 'Iamthelegend1!',\n",
       " 'afavin964',\n",
       " 'mark11',\n",
       " 'fk9qi21m',\n",
       " 'gedu1t1ah',\n",
       " 'utuham322',\n",
       " 'ihana906',\n",
       " 'j2yj2yj2y',\n",
       " 'wibi182d',\n",
       " 'han19660120',\n",
       " '929865yt',\n",
       " '64959rodro',\n",
       " 'hard7ware',\n",
       " 'rogyh820',\n",
       " 'bafiqkxwu0',\n",
       " 'sony18',\n",
       " 'ubojig109',\n",
       " 'zgmfnwuq25',\n",
       " 'njmania114',\n",
       " 'kevin24',\n",
       " 'cifinew817',\n",
       " '2akira2',\n",
       " 'djawl1228',\n",
       " 'islamasma12',\n",
       " 'u03kz6ez',\n",
       " 'a2531106',\n",
       " 'jonothepoop1',\n",
       " 'Oshity07142014',\n",
       " 'edcmki90',\n",
       " 'megdam55',\n",
       " 'yitbos77',\n",
       " '123456rajput',\n",
       " 'chiefwanker1',\n",
       " 'islamasma12',\n",
       " 'ravens11',\n",
       " 'plumilla1',\n",
       " 'ryjypes139',\n",
       " '4XakB8TkzOQWCS7Y',\n",
       " 'xiau5ff',\n",
       " 'bijou2012',\n",
       " '123net123',\n",
       " 'fudijep286',\n",
       " 'mpompo1',\n",
       " 'szdectoj2',\n",
       " 'jalal123456',\n",
       " 'szdectoj2',\n",
       " '1qa2ws3ed4rf',\n",
       " 'folashade1',\n",
       " 'medebizu3',\n",
       " '01161590m',\n",
       " 'gkhan01',\n",
       " '3f5xd41l0ik7',\n",
       " 'lqksuym982',\n",
       " 'admin123',\n",
       " 'zu20081965',\n",
       " 'elonex24',\n",
       " 'sd6x9s3s',\n",
       " 'jytifok873',\n",
       " 'barra23',\n",
       " 'juliana19',\n",
       " 'ass359',\n",
       " 'e667794c1d',\n",
       " 'pedronha96',\n",
       " '123net123',\n",
       " 'aliki123',\n",
       " 'ok>bdk',\n",
       " 'tahseen75',\n",
       " 'mtvwyz001',\n",
       " 'sofietou74',\n",
       " 'deivid1991',\n",
       " 'junaid5',\n",
       " 'vardhan19',\n",
       " 'pap0spep0s',\n",
       " 'natalia12',\n",
       " 'senghong2009',\n",
       " 'admin123',\n",
       " 'sebo82',\n",
       " '123456rajput',\n",
       " 'eeae14li',\n",
       " 'znbl5tj1',\n",
       " 'cigicigi123',\n",
       " 'jannia5',\n",
       " '01161590m',\n",
       " '23deagosto',\n",
       " 'kaiden12',\n",
       " 'before1go',\n",
       " 'iwaguh884',\n",
       " 'x8512514',\n",
       " 'vmdo3i',\n",
       " 'alhama11408',\n",
       " 'a8082855',\n",
       " '0169395484a',\n",
       " 'njmania114',\n",
       " 'njmania114',\n",
       " 'xie635891',\n",
       " 'gypz6526317',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # printing x list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # printing y list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE NEED TO APPLY TF-IDF(TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY) OF DATA\n",
    "# creating a custom function to split the word into characters\n",
    "def word_divide_char(inputs):\n",
    "    character=[]\n",
    "    for i in inputs:\n",
    "        character.append(i)\n",
    "    return character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'z', 'd', 'e', '5', '5', '7', '7']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_divide_char('kzde5577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we import TF-IDF vectorizer to convert String data into numerical data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(tokenizer=word_divide_char) # we tokenize the data on the basis of word_divide_char functon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply TF-IDF vectorizer on data, x(all passwords)\n",
    "X=vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669639, 128)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # second column size increased because it is now vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x04',\n",
       " '\\x05',\n",
       " '\\x06',\n",
       " '\\x08',\n",
       " '\\x0e',\n",
       " '\\x0f',\n",
       " '\\x10',\n",
       " '\\x16',\n",
       " '\\x17',\n",
       " '\\x19',\n",
       " '\\x1b',\n",
       " '\\x1c',\n",
       " '\\x1e',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names() # getting all the features of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x128 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector=X[0]\n",
    "first_document_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.56654815],\n",
       "        [0.        ],\n",
       "        [0.59189825],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.28568302],\n",
       "        [0.2212156 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.29215307],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.33582006],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector.T.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.591898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.335820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.292153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.285683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF-IDF\n",
       "7   0.591898\n",
       "5   0.566548\n",
       "z   0.335820\n",
       "k   0.292153\n",
       "d   0.285683\n",
       "..       ...\n",
       "<   0.000000\n",
       ";   0.000000\n",
       "9   0.000000\n",
       "8   0.000000\n",
       "   0.000000\n",
       "\n",
       "[128 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to prepare the data for modelling purpose with first column as feature, and second column as the importance of that feature\n",
    "# this is final data for modelling purpose\n",
    "df=pd.DataFrame(first_document_vector.T.todense(),index=vectorizer.get_feature_names(),columns=['TF-IDF'])\n",
    "df.sort_values(by=['TF-IDF'],ascending=False) # arranged the data in decreaing order of TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to pass this data for modelling purpose (Applying Machine Learning)\n",
    "# first we need to split the data for training and testing purpose\n",
    "# train - To learn the relationship within data, \n",
    "# test - To do predictions, and this testing data will be unseen to my model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2) # using train_test_split, we splitted the data, train - 80% of data, test - 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535711, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Creation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now after splitting our data is ready for modelling stuff\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=0,multi_class='multinomial') # we consider case of multinomial logistic regression, because we have three types of password - 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train) # fitting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have trained our data, so we consider some rare case which is not in data, and predicts its strength\n",
    "dt=np.array(['%@123abcd'])\n",
    "pred=vectorizer.transform(dt)\n",
    "clf.predict(pred) # returned 1 there fore password is of average strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same way we can do prediction on X test data, In the same we can also consider some of the advanced classifier, such as adabboost, catboost, randomforest\n",
    "y_pred=clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the LinearRegression model comes to be: \n",
      " \n",
      "0.819374625497703\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the LinearRegression model comes to be: \\n \") \n",
    "print(clf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model\n",
    "from sklearn.linear_model import Ridge\n",
    "reg2 = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting data into the model.\n",
    "reg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40173932, 0.32059335, 0.7318502 , ..., 0.69614871, 1.15097973,\n",
       "       0.531081  ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions \n",
    "pred2 = reg2.predict(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RidgeRegression model comes to be: \n",
      " \n",
      "0.4355095594487979\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the RidgeRegression model comes to be: \\n \") \n",
    "print(reg2.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decision Tree Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing decision tree regressor \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "dec = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting data into the model.\n",
    "dec.fit(X_train, y_train)\n",
    "# Making predictions on Test data \n",
    "pred3 = dec.predict(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree Regressor  model comes to be: \n",
      " \n",
      "0.9996059981507784\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the Decision Tree Regressor  model comes to be: \\n \") \n",
    "print(dec.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\t\t\t RootMeanSquareError \t\t Accuracy of the model\n",
      "Linear Regression \t\t 0.4283 \t \t\t 0.8194\n",
      "Ridge Regression \t\t 0.3831 \t \t\t 0.4355\n",
      "Decision Tree Regressor\t\t 0.1730 \t \t\t 0.9996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Model\\t\\t\\t RootMeanSquareError \\t\\t Accuracy of the model\") \n",
    "print(\"\"\"Linear Regression \\t\\t {:.4f} \\t \\t\\t {:.4f}\"\"\".format(  np.sqrt(mean_squared_error(y_test, y_pred)), clf.score(X_train,y_train)))\n",
    "print(\"\"\"Ridge Regression \\t\\t {:.4f} \\t \\t\\t {:.4f}\"\"\".format(  np.sqrt(mean_squared_error(y_test, pred2)), reg2.score(X_train,y_train)))\n",
    "print(\"\"\"Decision Tree Regressor\\t\\t {:.4f} \\t \\t\\t {:.4f}\"\"\".format(  np.sqrt(mean_squared_error(y_test, pred3)), dec.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of decision tree regressor is higher and root mean sqaure error is least.\n",
    "\n",
    "Thus, Decision tree regressor is more efficient model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
