{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COURSE:   PGP [AI&ML]\n",
    "## Learner :  Chaitanya Kumar Battula\n",
    "## Topic : Machine Learning\n",
    "##  Project  type: Practice Project \n",
    "## Project title: Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the reqired libraries\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.externals import joblib\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the dataset and add headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and give the column names\n",
    "columns=['userId', 'productId', 'ratings','timestamp']\n",
    "electronics_df=pd.read_csv('ratings_Electronics.csv',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the timestamp column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df.drop('timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of rows and columns\n",
    "rows,columns=electronics_df.shape\n",
    "print('Number of rows: ',rows)\n",
    "print('Number of columns: ',columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the datatypes\n",
    "electronics_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking subset of the dataset\n",
    "electronics_df1=electronics_df.iloc[:50000,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since the data is very big. Consider electronics_df1 named dataframe with  first 50000 rows and all columns from 0 of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics of rating variable\n",
    "electronics_df1['ratings'].describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the minimum and maximum ratings\n",
    "print('Minimum rating is: %d' %(electronics_df1.ratings.min()))\n",
    "print('Maximum rating is: %d' %(electronics_df1.ratings.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rating are on the scale 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "print('Number of missing values across columns: \\n',electronics_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are no missing records in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the rating\n",
    "with sns.axes_style('white'):\n",
    "    g = sns.factorplot(\"ratings\", data=electronics_df1, aspect=2.0,kind='count')\n",
    "    g.set_ylabels(\"Total number of ratings\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that more number of users have given the rating of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique user id  in the data\n",
    "print('Number of unique users in Raw data = ', electronics_df1['userId'].nunique())\n",
    "# Number of unique product id  in the data\n",
    "print('Number of unique product in Raw data = ', electronics_df1['productId'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Taking the subset of dataset to make it less sparse/ denser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the top 10 users based on ratings\n",
    "most_rated=electronics_df1.groupby('userId').size().sort_values(ascending=False)[:10]\n",
    "print('Top 10 users based on ratings: \\n',most_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=electronics_df1.userId.value_counts()\n",
    "electronics_df1_final=electronics_df1[electronics_df1.userId.isin(counts[counts>=15].index)]\n",
    "print('Number of users who have rated 25 or more items =', len(electronics_df1_final))\n",
    "print('Number of unique users in the final data = ', electronics_df1_final['userId'].nunique())\n",
    "print('Number of unique products in the final data = ', electronics_df1_final['userId'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* electronics_df1_final has the users who have rated 25 or more items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratings analysis in final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructing the pivot table\n",
    "final_ratings_matrix = electronics_df1_final.pivot(index = 'userId', columns ='productId', values = 'ratings').fillna(0)\n",
    "final_ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It shows that it is a sparse matrix. So, many cells are filled with 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that there are 7 products and 236 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calucating the density of the rating marix\n",
    "given_num_of_ratings = np.count_nonzero(final_ratings_matrix)\n",
    "print('given_num_of_ratings = ', given_num_of_ratings)\n",
    "possible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\n",
    "print('possible_num_of_ratings = ', possible_num_of_ratings)\n",
    "density = (given_num_of_ratings/possible_num_of_ratings)\n",
    "density *= 100\n",
    "print ('density: {:4.2f}%'.format(density))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The density value of the matrix also shows that it is a sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data randomnly into train and test datasets into 70:30 ratio\n",
    "train_data, test_data = train_test_split(electronics_df1_final, test_size = 0.3, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of training data: ',train_data.shape)\n",
    "print('Shape of testing data: ',test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Building Popularity Recommder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of user_id for each unique product as recommendation score \n",
    "train_data_grouped = train_data.groupby('productId').agg({'userId': 'count'}).reset_index()\n",
    "train_data_grouped.rename(columns = {'userId': 'score'},inplace=True)\n",
    "train_data_grouped.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the products on recommendation score \n",
    "train_data_sort = train_data_grouped.sort_values(['score', 'productId'], ascending = [0,1]) \n",
    "      \n",
    "#Generate a recommendation rank based upon score \n",
    "train_data_sort['rank'] = train_data_sort['score'].rank(ascending=0, method='first') \n",
    "          \n",
    "#Get the top 5 recommendations \n",
    "popularity_recommendations = train_data_sort.head(5) \n",
    "popularity_recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use popularity based recommender model to make predictions\n",
    "def recommend(user_id):     \n",
    "    user_recommendations = popularity_recommendations \n",
    "          \n",
    "    #Add user_id column for which the recommendations are being generated \n",
    "    user_recommendations['userId'] = user_id \n",
    "      \n",
    "    #Bring user_id column to the front \n",
    "    cols = user_recommendations.columns.tolist() \n",
    "    cols = cols[-1:] + cols[:-1] \n",
    "    user_recommendations = user_recommendations[cols] \n",
    "          \n",
    "    return user_recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_recom = [10,100,150]   # This list is user choice.\n",
    "for i in find_recom:\n",
    "    print(\"The list of recommendations for the userId: %d\\n\" %(i))\n",
    "    print(recommend(i))    \n",
    "    print(\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since, it is a Popularity recommender model, so, all the three users are given the same recommendations. Here, we predict the products based on the popularity. It is not personalized to particular user. It is a non-personalized recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Building Collaborative Filtering recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electronics_df_CF = pd.concat([train_data, test_data]).reset_index()\n",
    "electronics_df_CF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Based Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix with row per 'user' and column per 'item' \n",
    "pivot_df = electronics_df_CF.pivot(index = 'userId', columns ='productId', values = 'ratings').fillna(0)\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the pivot table: ', pivot_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define user index from 0 to 10\n",
    "pivot_df['user_index'] = np.arange(0, pivot_df.shape[0], 1)\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.set_index(['user_index'], inplace=True)\n",
    "# Actual ratings given by users\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As this is a sparse matrix we will use SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "U, sigma, Vt = svds(pivot_df, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Left singular matrix: \\n',U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sigma: \\n',sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As sigma is not a diagonal matrix we have to convert it into diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct diagonal array in SVD\n",
    "sigma = np.diag(sigma)\n",
    "print('Diagonal matrix: \\n',sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Right singular matrix: \\n',Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted ratings\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "# Convert predicted ratings to dataframe\n",
    "preds_df = pd.DataFrame(all_user_predicted_ratings, columns = pivot_df.columns)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend the items with the highest predicted ratings\n",
    "\n",
    "def recommend_items(userID, pivot_df, preds_df, num_recommendations):\n",
    "    # index starts at 0  \n",
    "    user_idx = userID-1 \n",
    "    # Get and sort the user's ratings\n",
    "    sorted_user_ratings = pivot_df.iloc[user_idx].sort_values(ascending=False)\n",
    "    #sorted_user_ratings\n",
    "    sorted_user_predictions = preds_df.iloc[user_idx].sort_values(ascending=False)\n",
    "    #sorted_user_predictions\n",
    "    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)\n",
    "    temp.index.name = 'Recommended Items'\n",
    "    temp.columns = ['user_ratings', 'user_predictions']\n",
    "    temp = temp.loc[temp.user_ratings == 0]   \n",
    "    temp = temp.sort_values('user_predictions', ascending=False)\n",
    "    print('\\nBelow are the recommended items for user(user_id = {}):\\n'.format(userID))\n",
    "    print(temp.head(num_recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 4\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 6\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 8\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since, it is a Collaborative recommender model, so, all the three users are given different recommendations based on users past behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation of Collabrative recommendation model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual ratings given by the users\n",
    "final_ratings_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average ACTUAL rating for each item\n",
    "final_ratings_matrix.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted ratings \n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average PREDICTED rating for each item\n",
    "preds_df.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df = pd.concat([final_ratings_matrix.mean(), preds_df.mean()], axis=1)\n",
    "rmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n",
    "print(rmse_df.shape)\n",
    "rmse_df['item_index'] = np.arange(0, rmse_df.shape[0], 1)\n",
    "rmse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = round((((rmse_df.Avg_actual_ratings - rmse_df.Avg_predicted_ratings) ** 2).mean() ** 0.5), 5)\n",
    "print('\\nRMSE SVD Model = {} \\n'.format(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Getting top - K ( K = 5) recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter 'userID' and 'num_recommendations' for the user #\n",
    "userID = 9\n",
    "num_recommendations = 5\n",
    "recommend_items(userID, pivot_df, preds_df, num_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Popularity-based recommender system is a non-personalised recommender system and these are based on frequecy counts, which may be not suitable to the user.We can see the differance above for the user id 4, 6 & 8, The Popularity based model has recommended the same set of 5 products to both but Collaborative Filtering based model has recommended entire different list based on the user past purchase history.\n",
    "\n",
    "* Model-based Collaborative Filtering is a personalised recommender system, the recommendations are based on the past behavior of the user and it is not dependent on any additional information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
