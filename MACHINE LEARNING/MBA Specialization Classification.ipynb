{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA Specialization Classification\n",
    "\n",
    "![](mba1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_score</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Percentage_in_10_Class</th>\n",
       "      <th>Percentage_in_12_Class</th>\n",
       "      <th>Percentage_in_Under_Graduate</th>\n",
       "      <th>percentage_MBA</th>\n",
       "      <th>post_score</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Previous_Degree</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Place_you_belong_to</th>\n",
       "      <th>perceived#Job#Skill</th>\n",
       "      <th>Specialization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.8</td>\n",
       "      <td>72.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>77.6</td>\n",
       "      <td>82.6</td>\n",
       "      <td>76.90</td>\n",
       "      <td>66.85</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Semi Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.666667</td>\n",
       "      <td>26</td>\n",
       "      <td>93.2</td>\n",
       "      <td>83.8</td>\n",
       "      <td>77.00</td>\n",
       "      <td>74.97</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>Female</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>desired skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>91.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>68.30</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>Single</td>\n",
       "      <td>Semi Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.666667</td>\n",
       "      <td>24</td>\n",
       "      <td>79.8</td>\n",
       "      <td>61.6</td>\n",
       "      <td>60.33</td>\n",
       "      <td>69.28</td>\n",
       "      <td>76.666667</td>\n",
       "      <td>Female</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pre_score  Age_in_years  Percentage_in_10_Class  Percentage_in_12_Class  \\\n",
       "0  75.000000            22                    71.0                    74.8   \n",
       "1  71.666667            25                    77.6                    82.6   \n",
       "2  76.666667            26                    93.2                    83.8   \n",
       "3  66.666667            22                    91.2                    80.0   \n",
       "4  71.666667            24                    79.8                    61.6   \n",
       "\n",
       "   Percentage_in_Under_Graduate  percentage_MBA  post_score  Gender  \\\n",
       "0                         72.00           61.00   83.333333    Male   \n",
       "1                         76.90           66.85   76.666667    Male   \n",
       "2                         77.00           74.97   75.000000  Female   \n",
       "3                         67.00           68.30   60.000000    Male   \n",
       "4                         60.33           69.28   76.666667  Female   \n",
       "\n",
       "          STATE Previous_Degree Marital_status Place_you_belong_to  \\\n",
       "0  Central Zone     Engineering         Single               Urban   \n",
       "1  Central Zone     Engineering         Single          Semi Urban   \n",
       "2  Central Zone     Engineering         Single               Urban   \n",
       "3  Central Zone        Commerce         Single          Semi Urban   \n",
       "4  Central Zone     Engineering         Single               Urban   \n",
       "\n",
       "  perceived#Job#Skill Specialization  \n",
       "0     prefered skills      Marketing  \n",
       "1     prefered skills            LOS  \n",
       "2      desired skills        Finance  \n",
       "3     prefered skills        Finance  \n",
       "4     prefered skills        Finance  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../DataSets/MBA_ADMISSIONS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.astype(int, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_score</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Percentage_in_10_Class</th>\n",
       "      <th>Percentage_in_12_Class</th>\n",
       "      <th>Percentage_in_Under_Graduate</th>\n",
       "      <th>percentage_MBA</th>\n",
       "      <th>post_score</th>\n",
       "      <th>Gender</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Previous_Degree</th>\n",
       "      <th>Marital_status</th>\n",
       "      <th>Place_you_belong_to</th>\n",
       "      <th>perceived#Job#Skill</th>\n",
       "      <th>Specialization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>83</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>25</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>66</td>\n",
       "      <td>76</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Semi Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>26</td>\n",
       "      <td>93</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>desired skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Commerce</td>\n",
       "      <td>Single</td>\n",
       "      <td>Semi Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>24</td>\n",
       "      <td>79</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>Central Zone</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Single</td>\n",
       "      <td>Urban</td>\n",
       "      <td>prefered skills</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pre_score  Age_in_years  Percentage_in_10_Class  Percentage_in_12_Class  \\\n",
       "0         75            22                      71                      74   \n",
       "1         71            25                      77                      82   \n",
       "2         76            26                      93                      83   \n",
       "3         66            22                      91                      80   \n",
       "4         71            24                      79                      61   \n",
       "\n",
       "   Percentage_in_Under_Graduate  percentage_MBA  post_score  Gender  \\\n",
       "0                            72              61          83    Male   \n",
       "1                            76              66          76    Male   \n",
       "2                            77              74          75  Female   \n",
       "3                            67              68          60    Male   \n",
       "4                            60              69          76  Female   \n",
       "\n",
       "          STATE Previous_Degree Marital_status Place_you_belong_to  \\\n",
       "0  Central Zone     Engineering         Single               Urban   \n",
       "1  Central Zone     Engineering         Single          Semi Urban   \n",
       "2  Central Zone     Engineering         Single               Urban   \n",
       "3  Central Zone        Commerce         Single          Semi Urban   \n",
       "4  Central Zone     Engineering         Single               Urban   \n",
       "\n",
       "  perceived#Job#Skill Specialization  \n",
       "0     prefered skills      Marketing  \n",
       "1     prefered skills            LOS  \n",
       "2      desired skills        Finance  \n",
       "3     prefered skills        Finance  \n",
       "4     prefered skills        Finance  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding out the correlation between the attributes of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_score</th>\n",
       "      <th>Age_in_years</th>\n",
       "      <th>Percentage_in_10_Class</th>\n",
       "      <th>Percentage_in_12_Class</th>\n",
       "      <th>Percentage_in_Under_Graduate</th>\n",
       "      <th>percentage_MBA</th>\n",
       "      <th>post_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pre_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250699</td>\n",
       "      <td>-0.140844</td>\n",
       "      <td>-0.191213</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.053699</td>\n",
       "      <td>0.265957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_in_years</th>\n",
       "      <td>0.250699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>-0.207313</td>\n",
       "      <td>-0.141367</td>\n",
       "      <td>0.296556</td>\n",
       "      <td>-0.036615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage_in_10_Class</th>\n",
       "      <td>-0.140844</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441987</td>\n",
       "      <td>0.410374</td>\n",
       "      <td>0.490386</td>\n",
       "      <td>-0.075099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage_in_12_Class</th>\n",
       "      <td>-0.191213</td>\n",
       "      <td>-0.207313</td>\n",
       "      <td>0.441987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.418453</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.052577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage_in_Under_Graduate</th>\n",
       "      <td>0.009590</td>\n",
       "      <td>-0.141367</td>\n",
       "      <td>0.410374</td>\n",
       "      <td>0.418453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363450</td>\n",
       "      <td>0.161584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_MBA</th>\n",
       "      <td>0.053699</td>\n",
       "      <td>0.296556</td>\n",
       "      <td>0.490386</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.363450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_score</th>\n",
       "      <td>0.265957</td>\n",
       "      <td>-0.036615</td>\n",
       "      <td>-0.075099</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>0.161584</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pre_score  Age_in_years  Percentage_in_10_Class  \\\n",
       "pre_score                      1.000000      0.250699               -0.140844   \n",
       "Age_in_years                   0.250699      1.000000                0.038332   \n",
       "Percentage_in_10_Class        -0.140844      0.038332                1.000000   \n",
       "Percentage_in_12_Class        -0.191213     -0.207313                0.441987   \n",
       "Percentage_in_Under_Graduate   0.009590     -0.141367                0.410374   \n",
       "percentage_MBA                 0.053699      0.296556                0.490386   \n",
       "post_score                     0.265957     -0.036615               -0.075099   \n",
       "\n",
       "                              Percentage_in_12_Class  \\\n",
       "pre_score                                  -0.191213   \n",
       "Age_in_years                               -0.207313   \n",
       "Percentage_in_10_Class                      0.441987   \n",
       "Percentage_in_12_Class                      1.000000   \n",
       "Percentage_in_Under_Graduate                0.418453   \n",
       "percentage_MBA                              0.286299   \n",
       "post_score                                  0.052577   \n",
       "\n",
       "                              Percentage_in_Under_Graduate  percentage_MBA  \\\n",
       "pre_score                                         0.009590        0.053699   \n",
       "Age_in_years                                     -0.141367        0.296556   \n",
       "Percentage_in_10_Class                            0.410374        0.490386   \n",
       "Percentage_in_12_Class                            0.418453        0.286299   \n",
       "Percentage_in_Under_Graduate                      1.000000        0.363450   \n",
       "percentage_MBA                                    0.363450        1.000000   \n",
       "post_score                                        0.161584        0.067904   \n",
       "\n",
       "                              post_score  \n",
       "pre_score                       0.265957  \n",
       "Age_in_years                   -0.036615  \n",
       "Percentage_in_10_Class         -0.075099  \n",
       "Percentage_in_12_Class          0.052577  \n",
       "Percentage_in_Under_Graduate    0.161584  \n",
       "percentage_MBA                  0.067904  \n",
       "post_score                      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the dataset for training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Percentage_in_10_Class','Percentage_in_Under_Graduate','Percentage_in_12_Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['percentage_MBA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train-test-split\"></a>\n",
    "**Training and Testing Dataset Spliting using the `train_test_split`**\n",
    "  \n",
    "  * Immporting the library from the sklearn.model_selection\n",
    "  * Split the dataset into 80:20 ratio\n",
    "  * x_train1 and y_train1 are the trainning datasets\n",
    "  * x_test1 and y_test1 are the testing datasets\n",
    "  * After the spliting of the datasets the model is ready to be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Algorithms\n",
    "Classification is a task that requires the use of machine learning algorithms that learn how to assign a class label to examples from the problem domain. An easy to understand example is classifying emails as “spam” or “not spam.”\n",
    "\n",
    "There are many different types of classification tasks that you may encounter in machine learning and specialized approaches to modeling that may be used for each.\n",
    "\n",
    "Here I am going to use 10 Classification algorithms, based on these the models will be trained and then evaluated using the accuracy scores.\n",
    "\n",
    "**The following models that we are going to use -**\n",
    "  * **Logistic Regression** : Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n",
    "  \n",
    "  \n",
    "  * **Decision Tree Classifier** : Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "  \n",
    "  \n",
    "  * **Random Forest Classifier** : Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.\n",
    "  \n",
    "  \n",
    "  * **Gausian NB** : This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning. This is especially useful when the whole dataset is too big to fit in memory at once. This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.\n",
    "  \n",
    "  \n",
    "  * **KNN algorithm** : K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories. K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "  \n",
    "  \n",
    "  * **Support Vector Machine Algorithm** : Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning. The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.\n",
    "  \n",
    "\n",
    "* **Stochastic Gradient Descent Classifier** : Stochastic Gradient Descent (SGD) is a simple yet efficient optimization algorithm used to find the values of parameters/coefficients of functions that minimize a cost function. In other words, it is used for discriminative learning of linear classifiers under convex loss functions such as SVM and Logistic regression.\n",
    "\n",
    "\n",
    "* **Linear Discriminant Analysis (LDA)** : Linear Discriminant Analysis (LDA) is a dimensionality reduction technique. As the name implies dimensionality reduction techniques reduce the number of dimensions (i.e. variables) in a dataset while retaining as much information as possible.\n",
    "\n",
    "\n",
    "* **Gradient Boosting** : Gradient boosting is a machine learning technique for regression, classification and other tasks, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.\n",
    "\n",
    "\n",
    "* **MLP Classifier** : Multi-layer perceptrons (MLP) make powerful classifiers that may provide superior performance compared with other classifiers, but are often criticized for the number of free parameters. Parameter selection for optimal performance is performed using measures that correlate well with generalisation error.\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "We are going to use these ten algorithms and based on the scores of the models the most fitted algorithm will be set! Now let's check out the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from os import path, makedirs, walk\n",
    "from joblib import dump, load\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression \n",
    "\n",
    "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(max_iter = 1000)\n",
    "logReg.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17894736842105263"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier Algorithm\n",
    "\n",
    "Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968421052631579"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train1, y_train1)\n",
    "dtc.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Marks</th>\n",
       "      <th>Predicted Marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Marks  Predicted Marks\n",
       "445            61               61\n",
       "253            66               66\n",
       "73             68               68\n",
       "406            69               69\n",
       "46             68               68\n",
       "..            ...              ...\n",
       "129            71               71\n",
       "231            71               73\n",
       "119            70               70\n",
       "399            77               77\n",
       "354            72               72\n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.round(dtc.predict(x_test1), decimals=2)\n",
    "pd.DataFrame({'Actual Marks': y_test1, 'Predicted Marks': y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Algorithm\n",
    "\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968421052631579"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train1, y_train1)\n",
    "rfc.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours Algorithm\n",
    "\n",
    "K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories. K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train1, y_train1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5368421052631579"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gausian NB Algorithm\n",
    "\n",
    "This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning. This is especially useful when the whole dataset is too big to fit in memory at once. This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22105263157894736"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Algorithm\n",
    "\n",
    "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning. The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3473684210526316"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "Gradient boosting is a machine learning technique for regression, classification and other tasks, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=300, learning_rate=1.0,max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=300,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37894736842105264"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier\n",
    "Multi-layer perceptrons (MLP) make powerful classifiers that may provide superior performance compared with other classifiers, but are often criticized for the number of free parameters. Parameter selection for optimal performance is performed using measures that correlate well with generalisation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1000, random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)\n",
    "Stochastic Gradient Descent (SGD) is a simple yet efficient optimization algorithm used to find the values of parameters/coefficients of functions that minimize a cost function. In other words, it is used for discriminative learning of linear classifiers under convex loss functions such as SVM and Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sdg = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08421052631578947"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis (LDA)\n",
    "Linear Discriminant Analysis (LDA) is a dimensionality reduction technique. As the name implies dimensionality reduction techniques reduce the number of dimensions (i.e. variables) in a dataset while retaining as much information as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16842105263157894"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.score(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Leading models are : Random Forest and Decision Tree\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
