{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1622313792622,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "cZOovifyYf1K",
    "outputId": "08af8745-41a2-4973-968e-33a5c98efae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "trainX = np.load(\"trainX.npy\",allow_pickle='TRUE')\n",
    "trainY = np.load(\"trainY.npy\",allow_pickle='TRUE')\n",
    "testX = np.load(\"testX.npy\",allow_pickle='TRUE')\n",
    "testY = np.load(\"testY.npy\",allow_pickle='TRUE')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622313792623,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "mWZL1623Yf1W"
   },
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(240,112,92,1)\n",
    "testX = testX.reshape(160,112,92,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622313792625,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "0hmEOerKYf1a",
    "outputId": "3d320fef-f005-4a7f-a304-3564afa69983"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=92x112 at 0x7F6E85F4D650>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.array_to_img(trainX[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyLCiNu2laTT"
   },
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622313793221,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "oyFnCvrDlaTV"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((112,92,1),input_shape=(112,92,1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
    "                                 kernel_size=(3,3), #Size of the filter\n",
    "                                 activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1622313793222,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "mN05mk8hlaTc"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(20, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1622313794569,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "mm1fHVpklaTf"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1622313796093,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "TlREpRGWlaTi",
    "outputId": "2cc14ff3-4b3c-4e4a-849f-7417ec005e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 112, 92, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 92, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 110, 90, 32)       320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 55, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 53, 43, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                276500    \n",
      "=================================================================\n",
      "Total params: 369,176\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kIsqrNElaTl"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3829,
     "status": "ok",
     "timestamp": 1622313835441,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "FsJI729klaTo",
    "outputId": "1a4bb065-b951-40c5-d555-07558379ba06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 7.9872e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9563\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 7.0060e-05 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9563\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 7.8027e-05 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9563\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.7422e-05 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9563\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 5.3932e-05 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9563\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.8081e-05 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9563\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 7.0913e-05 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9563\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 6.8600e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9563\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 6.4542e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9563\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 6.5741e-05 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9563\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 4.5622e-05 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9563\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 3.4498e-05 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9563\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 4.7092e-05 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9563\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 8.1859e-05 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9563\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 5.9992e-05 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9563\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 6.0885e-05 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9563\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 1.2044e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9563\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 8.2303e-05 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9563\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 3.6229e-05 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9563\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 1.1910e-04 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e83bf8cd0>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=20,\n",
    "          batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-RIB93faGCH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sxc6gOodhKi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622314362692,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "GSamc6CydiGH",
    "outputId": "f368fc8d-6b65-4f12-af12-3390261c9640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 10304)\n",
      "(240,)\n",
      "(160, 10304)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "trainX = np.load(\"trainX.npy\",allow_pickle='TRUE')\n",
    "trainY = np.load(\"trainY.npy\",allow_pickle='TRUE')\n",
    "testX = np.load(\"testX.npy\",allow_pickle='TRUE')\n",
    "testY = np.load(\"testY.npy\",allow_pickle='TRUE')\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)\n",
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=20)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1622314363958,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "kBeGTttxdiGJ"
   },
   "outputs": [],
   "source": [
    "trainX = trainX.reshape(240,112,92)\n",
    "testX = testX.reshape(160,112,92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1622314363959,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "_Y6rGhmOdnot"
   },
   "outputs": [],
   "source": [
    "trainX = np.repeat(trainX[..., np.newaxis], 3, -1)\n",
    "testX = np.repeat(testX[..., np.newaxis], 3, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1622314366232,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "pqILCnolukVz"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(include_top=False, #Do not include FC layer at the end\n",
    "                                          input_shape=(112,92, 3),\n",
    "                                          weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622314367730,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "5laT-kb-ukV4"
   },
   "outputs": [],
   "source": [
    "#Set pre-trained model layers to not trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622314368357,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "ctQSPmKOCjW4",
    "outputId": "32795ce2-72cb-4ce9-e413-e6ce94e0b233"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4, 3, 2048) dtype=float32 (created by layer 'conv5_block3_out')>"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdSlv9B8hs3K"
   },
   "source": [
    "### Add FC layer for new classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1622314369644,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "KuK7oJ-xhs3O"
   },
   "outputs": [],
   "source": [
    "#get Output layer of Pre0trained model\n",
    "x = model.output\n",
    "\n",
    "#Flatten the output to feed to Dense layer\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "#Add one Dense layer\n",
    "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "\n",
    "#Add output layer\n",
    "prediction = tf.keras.layers.Dense(20,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo6C0vDWhs3T"
   },
   "source": [
    "### Building final model for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1622314370256,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "ymVI9p5Shs3V"
   },
   "outputs": [],
   "source": [
    "#Using Keras Model class\n",
    "final_model = tf.keras.models.Model(inputs=model.input, #Pre-trained model input as input layer\n",
    "                                    outputs=prediction) #Output layer added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622314370257,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "xuUV2CXGhs3b"
   },
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622314370257,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "a1-rPTmIC3J0",
    "outputId": "c2378daa-bf16-42b3-e440-2b003866d3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 112, 92, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 98, 3)   0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 46, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 46, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 46, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 48, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 23, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 23, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 23, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 23, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 23, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 23, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 23, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 23, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 23, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 23, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 23, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 23, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 23, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 23, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 23, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 23, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 23, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 23, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 23, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 23, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 12, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 12, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 12, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 12, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 12, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 12, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 12, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 12, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 12, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 12, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 12, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 12, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 12, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 12, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 12, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 12, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 12, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 12, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 12, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 12, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 12, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 12, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 12, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 6, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 6, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 6, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 6, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 6, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 6, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 6, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 6, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 6, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 6, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 6, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 6, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 6, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 6, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 6, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 6, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 6, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 6, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 6, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 6, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 6, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 6, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 6, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 6, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 6, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 6, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 6, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 6, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 6, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 6, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 3, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 3, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 3, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 3, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 4, 3, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 3, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 3, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 4, 3, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 4, 3, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 3, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 3, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 3, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 3, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 3, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 3, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 4, 3, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 4, 3, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 4, 3, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 24576)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          4915400     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 20)           4020        dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,507,132\n",
      "Trainable params: 4,919,420\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNrdXkW_ukWC"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45443,
     "status": "ok",
     "timestamp": 1622314417004,
     "user": {
      "displayName": "Sayan Dey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgqVHJ9o6-7idGiRbNNd4iVc1VjzvuPnwmAnvEtD6U=s64",
      "userId": "03603580465490055794"
     },
     "user_tz": -330
    },
    "id": "RYoTWJrBcybp",
    "outputId": "c1af8e62-4651-4da2-be71-8fb4c500d4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 35s 97ms/step - loss: 6.1859 - accuracy: 0.4250 - val_loss: 1.3598 - val_accuracy: 0.7625\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.2207 - accuracy: 0.9333 - val_loss: 0.7540 - val_accuracy: 0.8438\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.0558 - accuracy: 0.9792 - val_loss: 0.0714 - val_accuracy: 0.9688\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9750\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9812\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 3.4723e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9937\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 1.4500e-04 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9937\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 1.1098e-04 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9937\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 9.7147e-05 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9937\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 8.4173e-05 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9937\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 7.5011e-05 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9937\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 6.8033e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9937\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 6.2205e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9937\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 5.7153e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9937\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 5.2996e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9937\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 4.9263e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9937\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 4.5968e-05 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 4.2936e-05 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 4.0319e-05 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 3.8144e-05 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e81c66150>"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "final_model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=20,\n",
    "          batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face Recognition Solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
